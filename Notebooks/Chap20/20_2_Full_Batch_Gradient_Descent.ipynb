{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vadhri/ai-notebook/blob/main/Notebooks/Chap20/20_2_Full_Batch_Gradient_Descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Notebook 20.2: Full Batch Gradient Descent**\n",
        "\n",
        "This notebook investigates training a network with full batch gradient descent as in figure 20.2.  There is also a version (notebook takes a long time to run), but this didn't speed it up much for me.  If you run out of CoLab time,  you'll need to download the Python file and run locally.\n",
        "\n",
        "Work through the cells below, running each cell in turn. In various places you will see the words \"TO DO\". Follow the instructions at these places and make predictions about what is going to happen or write code to complete the functions.\n",
        "\n",
        "Contact me at udlbookmail@gmail.com if you find any mistakes or have any suggestions."
      ],
      "metadata": {
        "id": "t9vk9Elugvmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this if you're in a Colab to install MNIST 1D repository\n",
        "!pip install git+https://github.com/greydanus/mnist1d"
      ],
      "metadata": {
        "id": "D5yLObtZCi9J",
        "outputId": "3b6d17b2-7220-4b56-c93b-8b6b2bb8de40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/greydanus/mnist1d\n",
            "  Cloning https://github.com/greydanus/mnist1d to /tmp/pip-req-build-ulpfzbwt\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/greydanus/mnist1d /tmp/pip-req-build-ulpfzbwt\n",
            "  Resolved https://github.com/greydanus/mnist1d to commit 7878d96082abd200c546a07a4101fa90b30fdf7e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from mnist1d==0.0.2.post16) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mnist1d==0.0.2.post16) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mnist1d==0.0.2.post16) (3.8.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mnist1d==0.0.2.post16) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mnist1d==0.0.2.post16) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mnist1d==0.0.2.post16) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mnist1d==0.0.2.post16) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mnist1d==0.0.2.post16) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mnist1d==0.0.2.post16) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mnist1d==0.0.2.post16) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mnist1d==0.0.2.post16) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mnist1d==0.0.2.post16) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->mnist1d==0.0.2.post16) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->mnist1d==0.0.2.post16) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->mnist1d==0.0.2.post16) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->mnist1d==0.0.2.post16) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mnist1d==0.0.2.post16) (1.16.0)\n",
            "Building wheels for collected packages: mnist1d\n",
            "  Building wheel for mnist1d (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mnist1d: filename=mnist1d-0.0.2.post16-py3-none-any.whl size=14628 sha256=c96052edf7babf7e2a885e81386d8d5ba9ad81ffdfc3b88a61273353da7ef506\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_tehsva9/wheels/41/95/55/45fcf7d38cfa97e35682da6c5017d4513729131326ce935371\n",
            "Successfully built mnist1d\n",
            "Installing collected packages: mnist1d\n",
            "Successfully installed mnist1d-0.0.2.post16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "import mnist1d\n",
        "import random\n",
        "from IPython.display import display, clear_output"
      ],
      "metadata": {
        "id": "YrXWAH7sUWvU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "bdPC9LhsOiL0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = mnist1d.data.get_dataset_args()\n",
        "data = mnist1d.data.get_dataset(args, path='./mnist1d_data.pkl', download=False, regenerate=False)\n",
        "print(data.keys())\n",
        "for k in data.keys():\n",
        "  if k != 'templates':\n",
        "    data[k] = torch.tensor(data[k], dtype=torch.float64).to(device)\n",
        "\n",
        "# The training and test input and outputs are in\n",
        "# data['x'], data['y']\n",
        "print(\"Examples in training set: {}\".format(len(data['y'])))\n",
        "print(\"Length of each example: {}\".format(data['x'].shape[-1]))"
      ],
      "metadata": {
        "id": "twI72ZCrCt5z",
        "outputId": "bf0824c1-d3e2-49df-b52f-afd6f35126dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded data from ./mnist1d_data.pkl\n",
            "dict_keys(['x', 'x_test', 'y', 'y_test', 't', 'templates'])\n",
            "Examples in training set: 4000\n",
            "Length of each example: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the network"
      ],
      "metadata": {
        "id": "_sFvRDGrl4qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data is length forty, and there are 10 classes\n",
        "D_i = 40\n",
        "D_o = 10\n",
        "\n",
        "# create model with one hidden layer and 298 hidden units\n",
        "model_1_layer = nn.Sequential(\n",
        "nn.Linear(D_i, 298),\n",
        "nn.ReLU(),\n",
        "nn.Linear(298, D_o)).to(device)\n",
        "\n",
        "\n",
        "# TODO -- create model with three hidden layers and 100 hidden units per layer\n",
        "\n",
        "model_2_layer = nn.Sequential(\n",
        "  nn.Linear(D_i, 100),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(100, 100),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(100, 100),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(100, D_o)\n",
        ").to(device)\n",
        "\n",
        "\n",
        "\n",
        "# TODO -- Create model with three hidden layers and 75 hidden units per layer\n",
        "# Replace this line\n",
        "model_3_layer = nn.Sequential(\n",
        "  nn.Linear(D_i, 75),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(75, 75),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(75, 75),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(75, D_o)\n",
        ").to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# TODO create model with four hidden layers and 63 hidden units per layer\n",
        "# Replace this line\n",
        "model_4_layer = nn.Sequential(\n",
        "  nn.Linear(D_i, 63),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(63, 63),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(63, 63),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(63, 63),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(63, D_o)\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "FslroPJJffrh"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# He initialization of weights\n",
        "def weights_init(layer_in):\n",
        "  if isinstance(layer_in, nn.Linear):\n",
        "    nn.init.kaiming_uniform_(layer_in.weight)\n",
        "    layer_in.bias.data.fill_(0.0)"
      ],
      "metadata": {
        "id": "YgLaex1pfhqz"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_data_x, train_data_y, n_epoch):\n",
        "  print(\"This is going to take a long time!\")\n",
        "  # choose cross entropy loss function (equation 5.24 in the loss notes)\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  # construct SGD optimizer and initialize learning rate to small value and momentum to 0\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr = 0.0025, momentum=0.0)\n",
        "  # create 100 dummy data points and store in data loader class\n",
        "  x_train = torch.tensor(train_data_x.t(), dtype=torch.float32)\n",
        "  y_train = torch.tensor(train_data_y, dtype=torch.long)\n",
        "\n",
        "  # load the data into a class that creates the batches -- full batch as there are 4000 examples\n",
        "  data_loader = DataLoader(TensorDataset(x_train,y_train), batch_size=4000, shuffle=False, worker_init_fn=np.random.seed(1))\n",
        "\n",
        "  # Initialize model weights\n",
        "  model.apply(weights_init)\n",
        "\n",
        "  # store the errors percentage at each point\n",
        "  errors_train = np.zeros((n_epoch))\n",
        "\n",
        "  for epoch in range(n_epoch):\n",
        "    # loop over batches\n",
        "    for i, data in enumerate(data_loader):\n",
        "      # retrieve inputs and labels for this batch\n",
        "      x_batch, y_batch = data\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "      # forward pass -- calculate model output\n",
        "      pred = model(x_batch)\n",
        "      # compute the loss\n",
        "      loss = loss_function(pred, y_batch)\n",
        "      # Store the errors\n",
        "      _, predicted_train_class = torch.max(pred.data, 1)\n",
        "      errors_train[epoch] = 100 - 100 * (predicted_train_class == y_train).float().sum() / len(y_train)\n",
        "      # backward pass\n",
        "      loss.backward()\n",
        "      # SGD update\n",
        "      optimizer.step()\n",
        "\n",
        "      if epoch % 10 == 0:\n",
        "        clear_output(wait=True)\n",
        "        display(\"Epoch %d, errors_train %3.3f\"%(epoch, errors_train[epoch]))\n",
        "\n",
        "  return errors_train"
      ],
      "metadata": {
        "id": "NYw8I_3mmX5c"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the data\n",
        "train_data_x = data['x'].t()\n",
        "train_data_y = data['y']\n",
        "# Print out sizes\n",
        "print(\"Train data: %d examples (columns), each of which has %d dimensions (rows)\"%((train_data_x.shape[1],train_data_x.shape[0])))"
      ],
      "metadata": {
        "id": "4FE3HQ_vedXO",
        "outputId": "0d1dd8b4-12c4-482f-e9f2-ef779f5ed3ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: 4000 examples (columns), each of which has 40 dimensions (rows)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the models\n",
        "errors_four_layers = train_model(model_4_layer, train_data_x, train_data_y, n_epoch=200000)"
      ],
      "metadata": {
        "id": "b56wdODqemF1",
        "outputId": "ddf133f9-7934-428c-c97e-681c1417e5ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Epoch 1180, errors_train 70.525'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errors_three_layers = train_model(model_3_layer, train_data_x, train_data_y, n_epoch=200000)\n"
      ],
      "metadata": {
        "id": "hqY-MJVPnCBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors_two_layers = train_model(model_2_layer, train_data_x, train_data_y, n_epoch=200000)\n"
      ],
      "metadata": {
        "id": "T61jfpNGnDGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors_one_layer = train_model(model_1_layer, train_data_x, train_data_y, n_epoch=500000)"
      ],
      "metadata": {
        "id": "HO8ZFgYqnEQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the results\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(errors_one_layer,'r-',label='one layer')\n",
        "ax.plot(errors_two_layers,'g-',label='two layers')\n",
        "ax.plot(errors_three_layers,'b-',label='three layers')\n",
        "ax.plot(errors_four_layers,'m-',label='four layers')\n",
        "ax.set_ylim(0,100)\n",
        "ax.set_xlabel('Epoch'); ax.set_ylabel('Percent error')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pYL0YMI5oNSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wJerga3M7eDw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}