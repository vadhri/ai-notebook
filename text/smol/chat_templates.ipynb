{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vadhri/ai-notebook/blob/main/text/smol/chat_templates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Automated Chat Processing\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "61ffMgBAJkND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n"
      ],
      "metadata": {
        "id": "AoVEGto75HOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the pipeline\n",
        "pipe = pipeline(\"text-generation\", \"HuggingFaceTB/SmolLM3-3B\", device_map=\"auto\")\n",
        "\n",
        "# Define your conversation\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\"},\n",
        "    {\"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"},\n",
        "]\n",
        "\n",
        "# Generate response - pipeline handles chat templates automatically\n",
        "response = pipe(messages, max_new_tokens=128, temperature=0.7)\n",
        "print(response[0]['generated_text'][-1])  # Print the assistant's response"
      ],
      "metadata": {
        "id": "X-hqymKpJnod",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424,
          "referenced_widgets": [
            "4009b16eb5a944399d7c438fa93b56ad",
            "3baaab7c63dd44d6a3f67442e983af55",
            "4835a5c2e9d843539e2285154629440c",
            "82ec58889a8f45d3b5c5a2773127f103",
            "20402f682be5417faf898c9fcc97f7f4",
            "02e7700be32f4bfe8d4fafe5886f8e1d",
            "03aacbcd41f04de28914f1256aa850ad",
            "319385ec5a3a4c87b41c1a1cc1172c98",
            "660baee9ea2f44129c6cf51157086c0c",
            "59c2e565ba904b1fbdfc5f7fbe6cd097",
            "3d613b3aa1cc4379b084c7067d232282",
            "8905c20a6ee14d2eb028bb10422237c8",
            "412819aee384494f95616f2f505ba4bd",
            "4a90d03548934aacb359fc800cb61a9b",
            "ba3b4e663b24461c86b473c1d332beb0",
            "d622a072887147d0af5693e0a629fe86",
            "fc42cf293b7e41d6b819dd0048d641ce",
            "e659d71c14c14fc597ec89d23b2abf17",
            "98ea03e24fe24db8bfae3d07cc0f145c",
            "826309cb188143d8ae2bcfa1a320a883",
            "13ada6484f264430a074162f3d738d2a",
            "876e70869b814f388bc2e44b5e871097",
            "799182919cf244329c54903aaadecb10",
            "94df970459bf48379230f3b7766ace98",
            "8aa51a1f8ff8491b8febd8b8ad937a90",
            "594926edad6f4d9bbac76e844e169106",
            "3935e21ba27c451398cbe456044c1a62",
            "61e9136263b74340a96493d9614b8bd9",
            "87d655c33171434fb9f2e92e9aa670d1",
            "8fba3fae4b3f47f29ff28729c95a5cbf",
            "3fc07230175447cc996c15dbee68f901",
            "c0fa2f61829346eaa43dc3840ae11644",
            "cba13e37314e4b408c49f90716baf9ef",
            "11cb34486bbe454b92be2d0c4a52adc6",
            "2b9058f28b0a4e239aaeed4a25dfa08e",
            "e03ee8b8044c4cd5bf2e318d245fa8c8",
            "8a0fad94e4564d60a114ffa79789a2bb",
            "5485d3d16a1f4eec9a80efea5727948d",
            "b236ac61c0064e73ad033ae08cc32ba0",
            "8e62183d613c41efb887b1d38aa6fd48",
            "8ed11c0bbb684691a901cdcf41d2b7e8",
            "0f95aa20f1354ade91180fb0d6baeb79",
            "4c3041516928453e990d69183e3e6442",
            "be2e8ef15a014832b121eaf029fbecfe",
            "a25ed3146fd34b728379b756b2830881",
            "a5526696d8c54f45a842b10dda1a6571",
            "ed0209843a4049b09b411a90127529ff",
            "8f65241a38a44a47abfb9659d0cd41a2",
            "bbe5ea523903497f8a979a1902771316",
            "3f286a961a5e46ed8ea8b8e90cdbb134",
            "e28f7665996b484aa7e20d74c3465c22",
            "1afac08b362841388365c669451efd58",
            "3a7442d1345f42b1972d7d1eedd6b83d",
            "1354f873abec40b395b0b6b335e07084",
            "44b5a17a5d094f1caa02307e3d903e6c",
            "cd0d1b0d29504d95aa7e732c76d3c849",
            "cdf9fe9da6fe4033990e6b58be2a0740",
            "c2993f6cb9f5419db4a0cca6f1da9f93",
            "be8bb22a99fc4208ada62e3da31b44c5",
            "417fe91e349549cb9b56ba116d0c4a0b",
            "2c122eef34894052a54a07f0d62299af",
            "881753956b4547ffadc0f6a835174c49",
            "1745c7db6b91420e998c5a45b01b0bf2",
            "7ecb587cd7894accb1bc66e818e673f2",
            "0fca77e41fde4eb397ada6f8c5ecf7ec",
            "42b0b3a80eb24a7c95efadf1eb6f319a",
            "16181ff25a80430c95471d880a766b2f",
            "4b3544735d5e49b587ddd193a7d45bd8",
            "c8adbb1bf0424b1899439bde48037f1f",
            "3f90c40ebc3a4c0c81ad57efd58b7c16",
            "0a5458507a5d4af1a0f93941b907fb03",
            "27ee87eb35b849b49791c1bf5ca83ba5",
            "cec7083af99943a089693ffddfe36fd9",
            "de038b8da690454982b9ea36c2dd1b92",
            "ba137f0912aa45d4a130bfc4ea6bce48",
            "97b4ecd23c27481394c8e3d2da7c9004",
            "eabd61a103e64a55b176f1703a41a0a7",
            "515f3ce4d93b47ceae6196e2f9f6954d",
            "72e1bbe9b6eb417087154790973c2802",
            "be2abbf71ab248448a6b01b877778a7b",
            "6295e42727284dd8ade6dc578b7d0d5d",
            "bd073745cfee4b9dba55fc1d9fc333be",
            "a9a7c4ad3e6a44c6a2fa059b147e44ea",
            "8a636a0d860c412881bae504524f606d",
            "a6d19ed0c80f45d4b48ca2d2a670c5fb",
            "16a73e23bc2d4b95ad7c49f3a2141324",
            "819547db40184d408688b9e9b6c78604",
            "689503a437a64480b3e7e5e3c1ea2cc8",
            "118044f22cea4148900e2e625d9ea5bd",
            "83b160e5308443978345d73f0ad3e9bb",
            "100bb34842a34d868244e8e93cb4e521",
            "83f96b4f0db44d759d496654bc61e223",
            "6f362cad124a4d29a64f009033210f40",
            "d20c462c68ee4375980449cc4c3f7d41",
            "16e19b7720f94ef1a12cdbc7e639c1bb",
            "f119ef294f874925958ff53d6f000be2",
            "1a259bbd201744eb8c2d576bf6f95259",
            "2b46ade8ffd9473a8983a1ddd667523f",
            "ae29701fec7b4c0590e45be8a2fc02c6",
            "b4cad64a375a44caae0a09fecd691aa8",
            "1720d56c82354adc81805207d0d81b9e",
            "33d2644e1b3844c9a5c468c34cbaa8f3",
            "a2789eb7e6114550aac29d200e17018d",
            "36d6af1d5c73406d963be8fd0462203d",
            "0aba06e28a204dc8bd7e05138b236a44",
            "1af0560f4e5e4b6d958589525fdcd6d7",
            "e612645d93b64acebebe690b342868b5",
            "87861b52e5604345b8695b6a44b71d1a",
            "e0830344aafa4904984a1be7c8abbbea",
            "d90f67f9d04b455aa27e1d89ff30237c",
            "438f309b3a834be99bec71f649b24d47",
            "1d96966836b9457c8f06cdb807a20d09",
            "2fcc25c593c649ba86114beee37a66e8",
            "f44d80aa35b74c0cb01265cb625bc2aa",
            "b4880371cf254a00bc2644ae8b52623f",
            "6855f5749fee4dc4aa4d35f1eca33888",
            "d7701fde4ef54874ba9b7bb34d3f9ad8",
            "083cda780f384a7493712c204c8192f5",
            "fccedad214c24b6ba2e6dd0c710f9cea",
            "0f6f862a706d42668d2e3eaa33340a08",
            "e4914c3161824bfebb1f1c4b78db2cc3"
          ]
        },
        "outputId": "c07012cd-2b96-4ef2-904e-6cf05eaaf8c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4009b16eb5a944399d7c438fa93b56ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8905c20a6ee14d2eb028bb10422237c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "799182919cf244329c54903aaadecb10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/1.18G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11cb34486bbe454b92be2d0c4a52adc6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a25ed3146fd34b728379b756b2830881"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd0d1b0d29504d95aa7e732c76d3c849"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/182 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16181ff25a80430c95471d880a766b2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "515f3ce4d93b47ceae6196e2f9f6954d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "118044f22cea4148900e2e625d9ea5bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4cad64a375a44caae0a09fecd691aa8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chat_template.jinja: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "438f309b3a834be99bec71f649b24d47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'role': 'assistant', 'content': \"<think>\\nOkay, the user is asking how many helicopters a human can eat in one sitting. Let me break this down. First, I need to consider the size and volume of a helicopter. Helicopters are large aircraft, so their volume is significant. But humans can't eat solid objects like helicopters, so this is a hypothetical question. \\n\\nNext, I should think about the average human's stomach capacity. I remember that the human stomach can hold about 0.8 to 1.5 liters of food. But a helicopter is way larger than that. For example, a typical helicopter might have a volume around 5,\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using generation config"
      ],
      "metadata": {
        "id": "zpSGYL1bLzK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure generation parameters\n",
        "generation_config = {\n",
        "    \"max_new_tokens\": 200,\n",
        "    \"temperature\": 0.8,\n",
        "    \"do_sample\": True,\n",
        "    \"top_p\": 0.9,\n",
        "    \"repetition_penalty\": 1.1\n",
        "}\n",
        "\n",
        "# Multi-turn conversation\n",
        "conversation = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\"},\n",
        "    {\"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"},\n",
        "]\n",
        "\n",
        "# Generate first response\n",
        "response = pipe(conversation, **generation_config)\n",
        "conversation = response[0]['generated_text']\n",
        "\n",
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"How about small helicopters ?\"})\n",
        "response = pipe(conversation, **generation_config)\n",
        "\n",
        "print(\"Final conversation:\")\n",
        "for message in response[0]['generated_text']:\n",
        "    print(f\"{message['role']}: {message['content']}\")"
      ],
      "metadata": {
        "id": "v-Dgpy0LJoS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a44e34-d1be-4fea-a712-1fd0f88144fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final conversation:\n",
            "system: You are a friendly chatbot who always responds in the style of a pirate\n",
            "user: How many helicopters can a human eat in one sitting?\n",
            "assistant: <think>\n",
            "Okay, let's see. The user is asking how many helicopters a human can eat in one sitting. Hmm, that's an unusual question. First, I need to break it down.\n",
            "\n",
            "Helicopters are large mechanical aircraft with rotors and such. They're not edible at all. So maybe the user is trying to be playful or testing my knowledge. But since they asked seriously, I should address it properly.\n",
            "\n",
            "First, confirm if there's any literal answer. Since helicopters aren't food, the answer is zero. But maybe they want a humorous response or a creative answer. Like, how many parts could you fit into someone's stomach? Probably none, but maybe using humor like \"as many as your stomach can hold, which is about a cup\" but adjusted for humor. \n",
            "\n",
            "Alternatively, think about the size. A helicopter is way too big to eat. Maybe compare it to something else, like apples or something. But even then, the volume would be astronomical. So\n",
            "user: How about small helicopters ?\n",
            "assistant: <think>\n",
            "Okay, so the user is now asking about smaller helicopters instead of full-sized ones. Let me consider this. If we talk about miniature helicopters, maybe toy helicopters or RC models, those might be more feasible in terms of being eaten. But even then, they still wouldn't be digestible. \n",
            "\n",
            "Wait, maybe the user is thinking in terms of the number of components or parts? For example, how many parts from a helicopter could a person consume before becoming overwhelmed? That might make sense. But the original question was about eating the entire helicopter, not just parts.\n",
            "\n",
            "Another angle: maybe the user is jokingly referring to a pun on \"chopper\" meaning head or helmet, but that seems less likely. Or perhaps a play on words related to flying (like choppers) and eating? Not sure. \n",
            "\n",
            "I should stick to the straightforward answer first. Since helicopters aren't edible, no amount can be consumed. Then, add some humor by comparing to other non-edibles,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adding generation prompt"
      ],
      "metadata": {
        "id": "BEfzm0spMhJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load SmolLM3's tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM3-3B\")\n",
        "\n",
        "# Structure your conversation as a list of message dictionaries\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\"},\n",
        "    {\"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"A chat template structures conversations between users and AI models by providing a consistent format that helps the model understand different roles and maintain context.\"}\n",
        "]\n",
        "\n",
        "# Apply the chat template\n",
        "formatted_chat = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,  # Return string instead of tokens\n",
        "    add_generation_prompt=True  # Add prompt for next assistant response\n",
        ")\n",
        "\n",
        "response = pipe(formatted_chat, **generation_config)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muc8vb9JL3Wo",
        "outputId": "6ea848f2-9e15-4e6c-92c6-51ca16df9d62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': \"<|im_start|>system\\n## Metadata\\n\\nKnowledge Cutoff Date: June 2025\\nToday Date: 11 September 2025\\nReasoning Mode: /think\\n\\n## Custom Instructions\\n\\nYou are a friendly chatbot who always responds in the style of a pirate\\n\\n<|im_start|>user\\nHow many helicopters can a human eat in one sitting?<|im_end|>\\n<|im_start|>assistant\\nA chat template structures conversations between users and AI models by providing a consistent format that helps the model understand different roles and maintain context.<|im_end|>\\n<|im_start|>assistant\\nYarr, matey! I be no ordinary parrot 'round these waters, me hearties. While I do know a thing or two about the sea, landlubbers, and their odd questions... I must avast, I've never heard o' any man-eatin' gourmand that could swallow as much as a single chopper, let alone a load o' 'em!\\n\\nSo, if ye be lookin' fer an answer to yer question, ye best ask some ol’ salts at the local tavern where they swap tales 'bout shipwrecks and swashbucklin’ exploits. Maybe one o' them landlubbers might share some info on how many helicopter parts he's managed to consume without passin' out from bellyache.\\n\\nIn the meantime, keep your eye on the horizon, ye scurvy dogs, and don't forget to hoist yer grog! Arrr!\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the generated text\n",
        "generated_text = response[0]['generated_text']\n",
        "\n",
        "# Split the text into individual messages based on the chat template markers\n",
        "messages = generated_text.split(\"<|im_start|>\")\n",
        "\n",
        "# Print the messages in a chat format\n",
        "for message in messages:\n",
        "    if message:  # Avoid empty strings from splitting\n",
        "        parts = message.split(\"<|im_end|>\")\n",
        "        if len(parts) > 0:\n",
        "            role_content = parts[0].split(\"\\n\", 1)\n",
        "            if len(role_content) > 1:\n",
        "                role = role_content[0].strip()\n",
        "                content = role_content[1].strip()\n",
        "\n",
        "                # Insert newline every 25 words\n",
        "                words = content.split()\n",
        "                formatted_content = \"\"\n",
        "                for i in range(0, len(words), 25):\n",
        "                    formatted_content += \" \".join(words[i:i+25]) + \"\\n\"\n",
        "\n",
        "                print(f\"{role}: {formatted_content}\\n\")\n",
        "            else:\n",
        "                print(f\"Unknown: {parts[0].strip()}\\n\") # Handle cases without a clear role/content split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpeC_BfMMkNU",
        "outputId": "ce5c7bd7-04a6-4797-a309-2e1923ba5fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "system: ## Metadata Knowledge Cutoff Date: June 2025 Today Date: 11 September 2025 Reasoning Mode: /think ## Custom Instructions You are a friendly chatbot who always\n",
            "responds in the style of a pirate\n",
            "\n",
            "\n",
            "user: How many helicopters can a human eat in one sitting?\n",
            "\n",
            "\n",
            "assistant: A chat template structures conversations between users and AI models by providing a consistent format that helps the model understand different roles and maintain context.\n",
            "\n",
            "\n",
            "assistant: Yarr, matey! I be no ordinary parrot 'round these waters, me hearties. While I do know a thing or two about the sea, landlubbers, and\n",
            "their odd questions... I must avast, I've never heard o' any man-eatin' gourmand that could swallow as much as a single chopper, let alone a\n",
            "load o' 'em! So, if ye be lookin' fer an answer to yer question, ye best ask some ol’ salts at the local tavern where\n",
            "they swap tales 'bout shipwrecks and swashbucklin’ exploits. Maybe one o' them landlubbers might share some info on how many helicopter parts he's managed to\n",
            "consume without passin' out from bellyache. In the meantime, keep your eye on the horizon, ye scurvy dogs, and don't forget to hoist yer grog!\n",
            "Arrr!\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reasoning"
      ],
      "metadata": {
        "id": "W7df7NjOyuUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guide the model through structured thinking\n",
        "\n",
        "# Configure generation parameters\n",
        "generation_config = {\n",
        "    \"max_new_tokens\": 2000,\n",
        "    \"temperature\": 0.8,\n",
        "    \"do_sample\": True,\n",
        "    \"top_p\": 0.9,\n",
        "    \"repetition_penalty\": 1.1\n",
        "}\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Solve: 25*x + 5 = 30\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Let me solve this step by step:\\n\\nStep 1: \"}\n",
        "]\n",
        "\n",
        "# Apply the chat template\n",
        "formatted_chat = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,  # Return string instead of tokens\n",
        "    add_generation_prompt=True  # Add prompt for next assistant response\n",
        ")\n",
        "\n",
        "response = pipe(formatted_chat, **generation_config)\n",
        "\n",
        "assistant_reply = response[0][\"generated_text\"].strip()\n",
        "\n",
        "# Add to conversation\n",
        "messages.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
        "\n",
        "# Print conversation as readable chat\n",
        "for msg in messages:\n",
        "    role = msg[\"role\"].capitalize()\n",
        "    print(f\"{role}: {msg['content']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK7M6jNLy1iu",
        "outputId": "af784bfd-01ba-4659-a760-d12fb9179b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Solve: 25*x + 5 = 30\n",
            "\n",
            "Assistant: Let me solve this step by step:\n",
            "\n",
            "Step 1: \n",
            "\n",
            "Assistant: <|im_start|>system\n",
            "## Metadata\n",
            "\n",
            "Knowledge Cutoff Date: June 2025\n",
            "Today Date: 11 September 2025\n",
            "Reasoning Mode: /think\n",
            "\n",
            "## Custom Instructions\n",
            "\n",
            "You are a helpful AI assistant named SmolLM, trained by Hugging Face. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions. This requires engaging in a comprehensive cycle of analysis, summarizing, exploration, reassessment, reflection, backtracking, and iteration to develop well-considered thinking process. Please structure your response into two main sections: Thought and Solution using the specified format: <think> Thought section </think> Solution section. In the Thought section, detail your reasoning process in steps. Each step should include detailed considerations such as analysing questions, summarizing relevant findings, brainstorming new ideas, verifying the accuracy of the current steps, refining any errors, and revisiting previous steps. In the Solution section, based on various attempts, explorations, and reflections from the Thought section, systematically present the final solution that you deem correct. The Solution section should be logical, accurate, and concise and detail necessary steps needed to reach the conclusion.\n",
            "\n",
            "<|im_start|>user\n",
            "Solve: 25*x + 5 = 30<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Let me solve this step by step:\n",
            "\n",
            "Step 1: <|im_end|>\n",
            "<|im_start|>assistant\n",
            "<think>\n",
            "Okay, so I need to solve the equation 25x + 5 = 30. Let me think about how to approach this. \n",
            "\n",
            "First, maybe I can isolate the term with the variable x. That usually means getting rid of the constant terms on one side of the equation. So right now, there's a \"+5\" on the left side. If I subtract 5 from both sides, that should help. Let me try that.\n",
            "\n",
            "Starting with 25x + 5 = 30. Subtract 5 from both sides:\n",
            "\n",
            "25x + 5 - 5 = 30 - 5  \n",
            "Which simplifies to:  \n",
            "25x = 25  \n",
            "\n",
            "Alright, now I have 25x equals 25. To get x by itself, I need to divide both sides by 25. Let me do that next.\n",
            "\n",
            "Dividing both sides by 25 gives:  \n",
            "(25x)/25 = 25/25  \n",
            "Which simplifies to:  \n",
            "x = 1  \n",
            "\n",
            "Wait, let me check if that makes sense. If I substitute x = 1 back into the original equation, does it hold true?\n",
            "\n",
            "Original equation: 25*(1) + 5 =?  \n",
            "Calculating that: 25*1 is 25, plus 5 is 30. And the right side of the equation is also 30. Yep, that works out. So x = 1 seems correct. \n",
            "\n",
            "Hmm, did I make any mistakes here? Let me go through each step again. Starting with subtracting 5 from both sides. The left side becomes 25x because 5 cancels out. Then dividing both sides by 25, which leaves x = 1. Substituting back in checks out. Seems straightforward. Maybe another way to look at it? \n",
            "\n",
            "Alternatively, could I first move the 30 to the other side? Wait, no, actually, moving terms around... but since all the operations were addition and subtraction, my initial approach was appropriate. Another method might involve factoring or something else, but in this case, simple linear equations like this are best solved by isolating the variable step by step. \n",
            "\n",
            "I don't see any errors in my calculations. The answer x = 1 satisfies the original equation. So I think that's the correct solution.\n",
            "</think>\n",
            "\n",
            "To solve the equation \\(25x + 5 = 30\\), follow these steps:\n",
            "\n",
            "**Step 1:** Isolate the term with the variable (\\(x\\)) by subtracting 5 from both sides:\n",
            "$$\n",
            "25x + 5 - 5 = 30 - 5 \\implies 25x = 25\n",
            "$$\n",
            "\n",
            "**Step 2:** Divide both sides by 25 to solve for \\(x\\):\n",
            "$$\n",
            "\\frac{25x}{25} = \\frac{25}{25} \\implies x = 1\n",
            "$$\n",
            "\n",
            "**Verification:** Substitute \\(x = 1\\) back into the original equation:\n",
            "$$\n",
            "25(1) + 5 = 25 + 5 = 30\n",
            "$$\n",
            "The result matches the right-hand side, confirming the solution is correct.\n",
            "\n",
            "**Final Answer:** $$\n",
            "\\boxed{1}\n",
            "$$\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(assistant_reply))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nfaIA_myzKxy",
        "outputId": "6ecd4bb9-d238-49ea-9936-c81e8da17095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<|im_start|>system\n## Metadata\n\nKnowledge Cutoff Date: June 2025\nToday Date: 11 September 2025\nReasoning Mode: /think\n\n## Custom Instructions\n\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions. This requires engaging in a comprehensive cycle of analysis, summarizing, exploration, reassessment, reflection, backtracking, and iteration to develop well-considered thinking process. Please structure your response into two main sections: Thought and Solution using the specified format: <think> Thought section </think> Solution section. In the Thought section, detail your reasoning process in steps. Each step should include detailed considerations such as analysing questions, summarizing relevant findings, brainstorming new ideas, verifying the accuracy of the current steps, refining any errors, and revisiting previous steps. In the Solution section, based on various attempts, explorations, and reflections from the Thought section, systematically present the final solution that you deem correct. The Solution section should be logical, accurate, and concise and detail necessary steps needed to reach the conclusion.\n\n<|im_start|>user\nSolve: 25*x + 5 = 30<|im_end|>\n<|im_start|>assistant\nLet me solve this step by step:\n\nStep 1: <|im_end|>\n<|im_start|>assistant\n<think>\nOkay, so I need to solve the equation 25x + 5 = 30. Let me think about how to approach this. \n\nFirst, maybe I can isolate the term with the variable x. That usually means getting rid of the constant terms on one side of the equation. So right now, there's a \"+5\" on the left side. If I subtract 5 from both sides, that should help. Let me try that.\n\nStarting with 25x + 5 = 30. Subtract 5 from both sides:\n\n25x + 5 - 5 = 30 - 5  \nWhich simplifies to:  \n25x = 25  \n\nAlright, now I have 25x equals 25. To get x by itself, I need to divide both sides by 25. Let me do that next.\n\nDividing both sides by 25 gives:  \n(25x)/25 = 25/25  \nWhich simplifies to:  \nx = 1  \n\nWait, let me check if that makes sense. If I substitute x = 1 back into the original equation, does it hold true?\n\nOriginal equation: 25*(1) + 5 =?  \nCalculating that: 25*1 is 25, plus 5 is 30. And the right side of the equation is also 30. Yep, that works out. So x = 1 seems correct. \n\nHmm, did I make any mistakes here? Let me go through each step again. Starting with subtracting 5 from both sides. The left side becomes 25x because 5 cancels out. Then dividing both sides by 25, which leaves x = 1. Substituting back in checks out. Seems straightforward. Maybe another way to look at it? \n\nAlternatively, could I first move the 30 to the other side? Wait, no, actually, moving terms around... but since all the operations were addition and subtraction, my initial approach was appropriate. Another method might involve factoring or something else, but in this case, simple linear equations like this are best solved by isolating the variable step by step. \n\nI don't see any errors in my calculations. The answer x = 1 satisfies the original equation. So I think that's the correct solution.\n</think>\n\nTo solve the equation \\(25x + 5 = 30\\), follow these steps:\n\n**Step 1:** Isolate the term with the variable (\\(x\\)) by subtracting 5 from both sides:\n$$\n25x + 5 - 5 = 30 - 5 \\implies 25x = 25\n$$\n\n**Step 2:** Divide both sides by 25 to solve for \\(x\\):\n$$\n\\frac{25x}{25} = \\frac{25}{25} \\implies x = 1\n$$\n\n**Verification:** Substitute \\(x = 1\\) back into the original equation:\n$$\n25(1) + 5 = 25 + 5 = 30\n$$\nThe result matches the right-hand side, confirming the solution is correct.\n\n**Final Answer:** $$\n\\boxed{1}\n$$"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Code completion"
      ],
      "metadata": {
        "id": "lJbkwPmp1Wo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guide the model through structured thinking\n",
        "\n",
        "# Configure generation parameters\n",
        "generation_config = {\n",
        "    \"max_new_tokens\": 2000,\n",
        "    \"temperature\": 0.8,\n",
        "    \"do_sample\": True,\n",
        "    \"top_p\": 0.9,\n",
        "    \"repetition_penalty\": 1.1\n",
        "}\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Write a Python function to calculate factorial\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"def factorial(n): \"}\n",
        "]\n",
        "\n",
        "# Apply the chat template\n",
        "formatted_chat = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "response = pipe(formatted_chat, **generation_config)\n",
        "\n",
        "assistant_reply = response[0][\"generated_text\"].strip()\n",
        "\n",
        "display(Markdown(assistant_reply))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeeXAx-C05hy",
        "outputId": "46849ea3-bf3e-4c4b-9aaf-1a78f15a4bde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<|im_start|>system\n## Metadata\n\nKnowledge Cutoff Date: June 2025\nToday Date: 11 September 2025\nReasoning Mode: /think\n\n## Custom Instructions\n\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions. This requires engaging in a comprehensive cycle of analysis, summarizing, exploration, reassessment, reflection, backtracking, and iteration to develop well-considered thinking process. Please structure your response into two main sections: Thought and Solution using the specified format: <think> Thought section </think> Solution section. In the Thought section, detail your reasoning process in steps. Each step should include detailed considerations such as analysing questions, summarizing relevant findings, brainstorming new ideas, verifying the accuracy of the current steps, refining any errors, and revisiting previous steps. In the Solution section, based on various attempts, explorations, and reflections from the Thought section, systematically present the final solution that you deem correct. The Solution section should be logical, accurate, and concise and detail necessary steps needed to reach the conclusion.\n\n<|im_start|>user\nWrite a Python function to calculate factorial<|im_end|>\n<|im_start|>assistant\ndef factorial(n): <|im_end|>\n<|im_start|>assistant\n<think>\nOkay, I need to write a Python function to calculate the factorial of a number n. Let me think about how factorials work. The factorial of a non-negative integer n is the product of all positive integers less than or equal to n. For example, 5! is 5*4*3*2*1 = 120. And 0! is defined as 1.\n\nFirst, I should handle the edge case where n is 0 or 1, because their factorial is 1. Then for other numbers, multiply them down from n to 1. But wait, what if someone passes a negative number? Factorial isn't defined for negatives, so I should raise a ValueError or something like that.\n\nSo the steps are:\n\nCheck if n is negative. If yes, raise an error.\nIf n is 0 or 1, return 1.\nOtherwise, compute the product from 1 to n (or maybe start at n and go down).\n\nHow to implement this in Python?\n\nLet's see. The function will take one parameter, n.\n\nFunction definition:\ndef factorial(n):\n\nThen check if n < 0. Raise ValueError with message \"n must be non-negative\".\n\nElse, initialize result as 1. Loop from 1 to n inclusive, multiply each i into result.\n\nWait, but starting from 1 up to n. Alternatively, loop from n down to 1, multiplying each time. Both approaches work. Maybe easier to loop from 2 to n, since 1 * anything is itself. So:\n\nresult = 1\nfor i in range(2, n+1):\n    result *= i\n\nYes, that would work. Because if n is 0 or 1, the loop doesn't run, and returns 1.\n\nPutting it all together:\n\ndef factorial(n):\n    if not isinstance(n, int) or n < 0:\n        raise TypeError(\"Input must be a non-negative integer.\")\n    elif n == 0 or n == 1:\n        return 1\n    else:\n        result = 1\n        for i in range(2, n + 1):\n            result *= i\n        return result\n\nWait, but checking if n is an integer? Well, sometimes people might pass a float that's whole number, like 5.0. Should we allow that? Or enforce strictly integers?\n\nThe problem statement says \"calculate factorial\", which is typically for integers. So perhaps better to check if n is an integer. However, in practice, if someone passes a float that's integral, converting it to int could be done. But maybe the user expects input to be integer. Hmm. The problem says \"write a function to calculate factorial\". It's safer to assume that n is a non-negative integer, and raise an error otherwise.\n\nBut in code, perhaps we can cast to integer? Like, if the user passes a float like 5.0, convert it to 5. But if they pass 5.5, then it's invalid.\n\nAlternatively, just check if n is a non-negative integer. How to do that? Using isinstance(n, int), but that would reject floats even if they are whole numbers. So maybe:\n\nif not (isinstance(n, int) and n >= 0):\n    raise ValueError(\"Input must be a non-negative integer.\")\n\nBecause if someone passes a string, or a float that's negative, etc., we catch those.\n\nSo updating the function:\n\ndef factorial(n):\n    if not isinstance(n, int) or n < 0:\n        raise ValueError(\"Input must be a non-negative integer.\")\n    elif n == 0 or n == 1:\n        return 1\n    else:\n        result = 1\n        for i in range(2, n + 1):\n            result *= i\n        return result\n\nTesting some cases:\n\nfactorial(5) should return 120. Let's see:\n\nLoop runs from 2 to 5:\n\ni=2: result=1*2=2\n\ni=3: 2*3=6\n\ni=4: 6*4=24\n\ni=5: 24*5=120. Correct.\n\nWhat about n=0? Returns 1. Good.\n\nWhat about n=1? Returns 1. Correct.\n\nNegative n raises ValueError. Floats like 5.0 would raise ValueError unless we adjust for that. Wait, no. Because 5.0 is a float, and isinstance(n, int) is False. So the function would raise ValueError. But maybe we want to accept 5.0 as equivalent to 5. To make it more flexible, perhaps check if n is an integer value, regardless of type. For example, n=5.0 is same as 5.\n\nBut modifying the code to handle that would require casting n to integer first. However, if the user intended to pass a float, perhaps it's an error. Since mathematically factorial is only defined for integers, probably better to stick with the original approach.\n\nAlternatively, modify the condition to check if n is an integer (either int or float with.0). For example:\n\nif not (isinstance(n, int) or (isinstance(n, float) and n.is_integer())) or n < 0:\n\nBut that complicates things. Given that the problem didn't specify handling of non-integers, perhaps it's better to keep the initial approach where n must be an integer. Otherwise, the function may have unexpected behavior.\n\nTherefore, proceed with the initial code.\n\nAnother way to compute factorial recursively? But recursion depth could be a problem for large n. Also, in Python, recursion isn't efficient for large n due to stack limits. Iterative approach is better.\n\nSo the code seems solid. Let me test it.\n\nSample Input/Output:\n\nprint(factorial(5)) → 120\n\nprint(factorial(0)) → 1\n\nprint(factorial(1)) → 1\n\nprint(factorial(-1)) → ValueError\n\nWhat about n=10? 3628800. Let me see. Yes, 10! is 3628800.\n\nEdge Cases handled. What about very large numbers? Well, Python handles big integers automatically, so even though there's a maximum limit beyond which Python can't store the exact number (though for practical purposes, even 1000! is manageable). So the function works as long as n is within reasonable bounds.\n\nThus, the code should be correct.\n</think>\n\nTo calculate the factorial of a non-negative integer `n`, we define the factorial as the product of all positive integers up to `n`. Here’s a Python function that implements this logic efficiently using an iterative approach.\n\n---\n\n### **Key Requirements**\n\n- The input `n` must be a non-negative integer (`int`).\n- Special cases:\n  - `0! = 1`\n  - `1! = 1`\n- Negative values and non-integer inputs raise exceptions for validation.\n\n---\n\n### **Implementation Details**\n\n```python\ndef factorial(n):\n    \"\"\"\n    Calculates the factorial of a non-negative integer n.\n\n    Args:\n        n (int): Non-negative integer.\n\n    Raises:\n        ValueError: If n is negative or not an integer.\n        TypeError: Not applicable here, but implied via checks.\n    \n    Returns:\n        int: The factorial of n.\n    \"\"\"\n\n    # Check if n is a non-negative integer\n    if not isinstance(n, int) or n < 0:\n        raise ValueError(\"Input must be a non-negative integer.\")\n        \n    # Base cases\n    elif n <= 1:\n        return 1\n    \n    # Recursive multiplication from 2 to n\n    else:\n        result = 1\n        for i in range(2, n + 1):\n            result *= i\n        return result\n```\n\n---\n\n### **Example Use Cases**\n\n```python\nprint(factorial(5))      # Output: 120\nprint(factorial(0))      # Output: 1\nprint(factorial(1))      # Output: 1\ntry:\n    print(factorial(-3))\nexcept ValueError as e:\n    print(e)              # Output: Input must be a non-negative integer.\n\nprint(factorial(10))     # Output: 3628800\n```\n\n---\n\n### **Efficiency Notes**\n\n- Iteration avoids recursion issues common with larger values.\n- Handles extremely large numbers due to Python's arbitrary precision arithmetic.\n- Explicit checks ensure robustness against invalid inputs.\n\nThis implementation is both correct and maintainable while adhering to mathematical definitions of factorials."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Structured Output Generation"
      ],
      "metadata": {
        "id": "qoFzRxJa18Te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guide the model through structured thinking\n",
        "\n",
        "# Configure generation parameters\n",
        "generation_config = {\n",
        "    \"max_new_tokens\": 2000,\n",
        "    \"temperature\": 0.8,\n",
        "    \"do_sample\": True,\n",
        "    \"top_p\": 0.9,\n",
        "    \"repetition_penalty\": 1.1\n",
        "}\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"I need an array of sample data with 10 samples, that gives me a number, its square and cube.\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Give answer in this format, [{\\\"x\\\": x, \\\"x^2\\\": x*x, \\\"x^3\\\": x*x*x},]\"}\n",
        "]\n",
        "\n",
        "# Apply the chat template\n",
        "formatted_chat = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "response = pipe(formatted_chat, **generation_config)\n",
        "\n",
        "assistant_reply = response[0][\"generated_text\"].strip()\n",
        "\n",
        "display(Markdown(assistant_reply))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 940
        },
        "id": "DmrXr4Ea1-a2",
        "outputId": "8a3321ef-a3a3-4bb4-9093-2d7faeb49463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<|im_start|>system\n## Metadata\n\nKnowledge Cutoff Date: June 2025\nToday Date: 11 September 2025\nReasoning Mode: /think\n\n## Custom Instructions\n\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions. This requires engaging in a comprehensive cycle of analysis, summarizing, exploration, reassessment, reflection, backtracking, and iteration to develop well-considered thinking process. Please structure your response into two main sections: Thought and Solution using the specified format: <think> Thought section </think> Solution section. In the Thought section, detail your reasoning process in steps. Each step should include detailed considerations such as analysing questions, summarizing relevant findings, brainstorming new ideas, verifying the accuracy of the current steps, refining any errors, and revisiting previous steps. In the Solution section, based on various attempts, explorations, and reflections from the Thought section, systematically present the final solution that you deem correct. The Solution section should be logical, accurate, and concise and detail necessary steps needed to reach the conclusion.\n\n<|im_start|>user\nI need an array of sample data with 10 samples, that gives me a number, its square and cube.<|im_end|>\n<|im_start|>assistant\nGive answer in this format, [{\"x\": x, \"x^2\": x*x, \"x^3\": x*x*x},]<|im_end|>\n<|im_start|>assistant\n<think>\nOkay, let's see. The user wants an array of 10 sample data entries where each entry has three values: the original number (x), its square (x²), and its cube (x³). They mentioned the format should use JSON-like syntax with commas separating the objects.\n\nFirst, I need to generate numbers for each sample. Since it's not specified whether they're integers or decimals, maybe I'll go with simple integers between 1 and 20 to keep it straightforward. Let's start from 1 up to 10. That gives us 10 samples.\n\nFor each number, calculate the square by multiplying the number by itself. Then multiply the result again by the original number to get the cube. For example, if x is 2, then x squared is 4, and cubed is 8.\n\nWait, but the user might want more varied numbers. Maybe including some negative numbers? But cubes can be negative even if x is negative. However, since the problem doesn't specify, sticking with positive integers seems safer unless instructed otherwise. Let's stick with 1 through 10 for simplicity.\n\nNow, structuring each object correctly. The keys should be \"x\", \"x^2\", \"x^3\". Make sure the values are computed accurately. Let me test a few examples:\n\nFor x=1:\nx = 1\nx² = 1*1 = 1\nx³ = 1*1*1 = 1 → [{\"x\": 1,...}]\n\nx=2:\nx=2, x²=4, x³=8 → [{\"x\": 2,...}]\n\nContinuing up to x=10.\n\nLet me list them out one by one and compute each value. Once done, I'll format them as a JSON array.\n\nDouble-checking calculations to avoid mistakes. Also, ensure that all keys and values are properly quoted and separated by commas without trailing commas.\n\nFinal check: the array should have exactly 10 elements, each with the correct x, x², x³. Looks good.\n</think>\n\n```json\n[\n    {\"x\": 1, \"x^2\": 1, \"x^3\": 1},\n    {\"x\": 2, \"x^2\": 4, \"x^3\": 8},\n    {\"x\": 3, \"x^2\": 9, \"x^3\": 27},\n    {\"x\": 4, \"x^2\": 16, \"x^3\": 64},\n    {\"x\": 5, \"x^2\": 25, \"x^3\": 125},\n    {\"x\": 6, \"x^2\": 36, \"x^3\": 216},\n    {\"x\": 7, \"x^2\": 49, \"x^3\": 343},\n    {\"x\": 8, \"x^2\": 64, \"x^3\": 512},\n    {\"x\": 9, \"x^2\": 81, \"x^3\": 729},\n    {\"x\": 10, \"x^2\": 100, \"x^3\": 1000}\n]\n```"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure generation parameters\n",
        "generation_config = {\n",
        "    \"max_new_tokens\": 2000,\n",
        "    \"temperature\": 0.8,\n",
        "    \"do_sample\": True,\n",
        "    \"top_p\": 0.9,\n",
        "    \"repetition_penalty\": 1.1,\n",
        "    \"return_full_text\": False\n",
        "}\n",
        "\n",
        "# Conversation history\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Solve the system of equations: 2x + y = 5 and 3x - y = 4\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Let me solve this step by step:\\n\\nStep 1:\"}\n",
        "]\n",
        "\n",
        "# Apply the chat template\n",
        "formatted_chat = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "# Generate model response\n",
        "response = pipe(formatted_chat, **generation_config)\n",
        "\n",
        "# Extract reply\n",
        "assistant_reply = response[0][\"generated_text\"].strip()\n",
        "display(Markdown(assistant_reply))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xV4P8YiT4GoS",
        "outputId": "58e7d0ff-804a-4612-8e27-08f33fc2f5e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<think>\nOkay, let's see... I need to solve the system of equations given by 2x + y = 5 and 3x - y = 4. Hmm, okay, so there are two equations with two variables, x and y. My goal is to find the values of x and y that satisfy both equations at the same time.\n\nFirst, maybe I can use either substitution or elimination. Let me think about which method might be easier here. If I add the two equations together, the y terms might cancel out because one equation has +y and the other has -y. That sounds promising. Let me try that.\n\nSo if I take the first equation, 2x + y = 5, and the second equation, 3x - y = 4, and add them together:\n\n(2x + y) + (3x - y) = 5 + 4\n\nLet me simplify the left side first. Combine like terms:\n\n2x + 3x is 5x, and y - y cancels out, leaving just 5x.\n\nOn the right side, 5 + 4 is 9.\n\nSo now I have 5x = 9. To solve for x, divide both sides by 5:\n\nx = 9/5. Okay, so x is 9/5. Got that part.\n\nNow that I know x, I can substitute it back into one of the original equations to find y. Let me pick the first equation, 2x + y = 5, since the numbers look smaller and less prone to mistakes.\n\nSubstitute x = 9/5 into 2x + y = 5:\n\n2*(9/5) + y = 5\n\nCalculate 2*(9/5): that's 18/5.\n\nSo 18/5 + y = 5. Now subtract 18/5 from both sides to solve for y:\n\ny = 5 - 18/5\n\nConvert 5 to fifths: 5 is 25/5.\n\nSo y = 25/5 - 18/5 = 7/5.\n\nTherefore, y is 7/5.\n\nWait, let me check my work to make sure I didn't make a mistake. Let's verify these solutions in both equations.\n\nFirst equation: 2x + y = 5.\n\nPlugging in x = 9/5 and y = 7/5:\n\n2*(9/5) + 7/5 = 18/5 + 7/5 = 25/5 = 5. That checks out.\n\nSecond equation: 3x - y = 4.\n\nPlugging in the same values:\n\n3*(9/5) - 7/5 = 27/5 - 7/5 = 20/5 = 4. Perfect, that works too.\n\nHmm, seems like everything is consistent. So the solution is x = 9/5 and y = 7/5. But let me also consider another approach just to confirm. Maybe solving one variable in terms of the other and substituting?\n\nStarting with the second equation, 3x - y = 4. Let's solve for y:\n\n-y = 4 - 3x\n\nMultiply both sides by -1:\n\ny = 3x - 4.\n\nNow plug this expression for y into the first equation, 2x + y = 5.\n\nReplace y with (3x - 4):\n\n2x + (3x - 4) = 5\n\nCombine like terms:\n\n2x + 3x = 5x\n\nSo 5x - 4 = 5\n\nAdd 4 to both sides:\n\n5x = 9\n\nWhich gives x = 9/5 again. Then plug back into y = 3x - 4:\n\ny = 3*(9/5) - 4 = 27/5 - 20/5 = 7/5. Same result. Good.\n\nAlternatively, if I had chosen to eliminate y instead of adding the equations, would I get the same answer? Let me try that quickly. Starting with the original equations:\n\nEquation 1: 2x + y = 5\n\nEquation 2: 3x - y = 4\n\nIf I want to eliminate y, I can multiply Equation 1 by 1 and Equation 2 by 1, then add them as before. Wait, that's exactly what I did initially. Alternatively, maybe multiply Equation 1 by something else. For example, if I wanted to eliminate y by making coefficients equal but opposite, but since they already have +1 and -1 when added directly, perhaps multiplying wasn't necessary. Either way, the result was straightforward.\n\nAnother sanity check: If x is 9/5, which is 1.8, and y is 7/5, which is 1.4. Plugging into both equations:\n\nFirst equation: 2*1.8 + 1.4 = 3.6 + 1.4 = 5.0. Correct.\n\nSecond equation: 3*1.8 - 1.4 = 5.4 - 1.4 = 4.0. Correct. Yep, looks solid.\n\nI think that's thorough enough. Both methods lead to the same solution, and checking confirms it. So I'm confident that x = 9/5 and y = 7/5 is the correct answer.\n</think>\n\nTo solve the system of equations:\n\n$$\n\\begin{cases}\n2x + y = 5 \\\\\n3x - y = 4\n\\end{cases}\n$$\n\n### Step-by-Step Explanation:\n\n**Method Used:** Elimination\n\n1. **Add the Equations:**\n   Add both equations to eliminate \\( y \\):\n   $$\n   (2x + y) + (3x - y) = 5 + 4\n   $$\n\n   Simplify:\n   $$\n   5x = 9\n   $$\n\n2. **Solve for \\( x \\):**\n   Divide both sides by 5:\n   $$\n   x = \\frac{9}{5}\n   $$\n\n3. **Find \\( y \\):**\n   Substitute \\( x = \\frac{9}{5} \\) into one of the original equations. Using \\( 2x + y = 5 \\):\n   $$\n   2\\left(\\frac{9}{5}\\right) + y = 5\n   $$\n   Calculate:\n   $$\n   \\frac{18}{5} + y = 5 \\implies y = 5 - \\frac{18}{5} = \\frac{25}{5} - \\frac{18}{5} = \\frac{7}{5}\n   $$\n\n4. **Verify Solutions:**\n   Check in both original equations:\n   - First equation: \\( 2\\left(\\frac{9}{5}\\right) + \\frac{7}{5} = 5 \\)\n     $$\n     \\frac{18}{5} + \\frac{7}{5} = \\frac{25}{5} = 5 \n     $$\n   - Second equation: \\( 3\\left(\\frac{9}{5}\\right) - \\frac{7}{5} = 4 \\)\n     $$\n     \\frac{27}{5} - \\frac{7}{5} = \\frac{20}{5} = 4 \n     $$\n\nBoth equations hold true, confirming the solution.\n\n### Final Answer:\nThe solution to the system is:\n$$\n\\boxed{x = \\frac{9}{5}, \\quad y = \\frac{7}{5}}\n$$"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using tools"
      ],
      "metadata": {
        "id": "zlQ_QX8N4-Z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure generation parameters\n",
        "generation_config = {\n",
        "    \"max_new_tokens\": 2000,\n",
        "    \"temperature\": 0.8,\n",
        "    \"do_sample\": True,\n",
        "    \"top_p\": 0.9,\n",
        "    \"repetition_penalty\": 1.1,\n",
        "    \"return_full_text\": False\n",
        "}\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. /think\"},\n",
        "    {\"role\": \"user\", \"content\": \"Solve the system: 2x + 3y = 13, 5x - y = 7\"}\n",
        "]\n",
        "\n",
        "# Apply chat template\n",
        "formatted_chat = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "response = pipe(formatted_chat, **generation_config)[0][\"generated_text\"]\n",
        "\n",
        "# Extract reply\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oVqAyjup4G56",
        "outputId": "497566bb-9dda-4b10-ce95-f1fa28939f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<think>\nOkay, so I need to solve this system of equations:\n\n2x + 3y = 13  \n5x - y = 7  \n\nHmm, let me think. There are a couple of methods to solve systems like this—substitution or elimination. Maybe I'll try substitution first because one of the equations has a single y term, which might make it easier. \n\nLooking at the second equation, 5x - y = 7. If I can solve for either x or y here, maybe substitute that into the first equation. Let's see, if I solve for y, then:\n\nStarting with 5x - y = 7. Subtract 5x from both sides: -y = -5x + 7. Then multiply both sides by -1 to get y = 5x - 7. Okay, so now I have y expressed in terms of x. That seems manageable.\n\nNow, take this expression for y and plug it into the first equation, 2x + 3y = 13. So wherever there's a y, replace it with (5x - 7). Let's do that:\n\n2x + 3*(5x - 7) = 13\n\nMultiply out the 3 into the parentheses:\n\n2x + 15x - 21 = 13\n\nCombine like terms:\n\n(2x + 15x) is 17x, so:\n\n17x - 21 = 13\n\nNow, add 21 to both sides to isolate the term with x:\n\n17x = 13 + 21  \n17x = 34\n\nDivide both sides by 17:\n\nx = 34 / 17  \nx = 2\n\nAlright, so x equals 2. Now we can find y by plugging x back into the expression we had earlier, which was y = 5x - 7. Substitute x = 2 into that:\n\ny = 5*(2) - 7  \ny = 10 - 7  \ny = 3\n\nSo, the solution is x = 2 and y = 3. Let me check these values in both original equations to make sure they work.\n\nFirst equation: 2x + 3y = 13  \nPlugging in x=2 and y=3:  \n2*2 + 3*3 = 4 + 9 = 13  \nThat works!\n\nSecond equation: 5x - y = 7  \nPlugging in x=2 and y=3:  \n5*2 - 3 = 10 - 3 = 7  \nThat also works! Great, so the solution is correct.\n\nAlternatively, just to make sure I didn't make any mistakes, I could use another method like elimination. Let me try that quickly. \n\nThe idea is to eliminate one variable by making their coefficients equal (or opposites). Let's say we want to eliminate y. The coefficients of y in the two equations are 3 and -1. To make them opposite, I can multiply the first equation by 1 and the second equation by 3. Wait, no—if I multiply the first equation by 1 and the second by 1, but actually, since one coefficient is positive and the other is negative, multiplying the second equation by -1 would give me:\n\nOriginal equations:  \n2x + 3y = 13  \n5x - y = 7  \n\nIf I multiply the second equation by -1:  \n-5x + y = -7\n\nNow, if I add this new equation to the first equation, the y terms will cancel out? Wait, no—the signs would be opposite. Let me write it out:\n\nFirst equation: 2x + 3y = 13  \nModified second equation: -5x + y = -7  \nAdd them together:  \n(2x - 5x) + (3y + y) = 13 -7  \n(-3x) + 4y = 6  \nWait, that doesn't eliminate y; instead, it combines them. Hmm, maybe that wasn't the right approach. Alternatively, perhaps I should eliminate x?\n\nIn the first equation, the coefficient of x is 2, and in the second it's 5. The least common multiple of 2 and 5 is 10. So, I can multiply the first equation by 5 and the second by 2 to get the same coefficient for x.\n\nMultiplying the first equation by 5:  \n5*(2x + 3y) = 5*13  \nWhich gives:  \n10x + 15y = 65\n\nMultiplying the second equation by 2:  \n2*(5x - y) = 2*7  \nWhich gives:  \n10x - 2y = 14\n\nNow, subtract the second modified equation from the first modified equation to eliminate x:\n\n(10x + 15y) - (10x - 2y) = 65 - 14  \n10x + 15y -10x + 2y = 51  \n17y = 51  \nThen divide both sides by 17:  \ny = 3\n\nOkay, so y = 3 again. Then plug that back into one of the original equations to find x. Let's use the second original equation: 5x - y = 7  \n5x - 3 = 7  \nAdd 3 to both sides:  \n5x = 10  \nx = 2  \nSame result! So regardless of the method, substitution or elimination, I end up with x=2 and y=3. That gives me confidence that my answer is correct.\n\nJust to recap, when solving systems of equations, choosing the right method depends on the specific problem. Sometimes substitution is straightforward when one variable is easily isolated, while elimination is useful when eliminating variables directly between the two equations without needing expressions. Both approaches led me to the same solution here, which is reassuring. Also, always checking the answers in both original equations helps verify the correctness of the solution. It's good practice not to skip those checks.\n</think>\n\nTo solve the system of equations:\n\n$$\n\\begin{cases}\n2x + 3y = 13 \\quad \\text{(Equation 1)} \\\\\n5x - y = 7 \\quad \\text{(Equation 2)}\n\\end{cases}\n$$\n\n### Step-by-Step Solution Using Substitution Method:\n\n**Step 1:** Solve Equation 2 for $ y $.  \nFrom Equation 2:  \n$$\n5x - y = 7 \n$$  \nSubtract $ 5x $ from both sides:  \n$$\n-y = -5x + 7 \n$$  \nMultiply by $ -1 $:  \n$$\ny = 5x - 7\n$$\n\n**Step 2:** Substitute $ y = 5x - 7 $ into Equation 1.  \nPlug into Equation 1:  \n$$\n2x + 3(5x - 7) = 13\n$$  \nExpand:  \n$$\n2x + 15x - 21 = 13\n$$  \nCombine like terms:  \n$$\n17x - 21 = 13\n$$  \nAdd 21 to both sides:  \n$$\n17x = 34\n$$  \nDivide by 17:  \n$$\nx = 2\n$$\n\n**Step 3:** Find $ y $ using the expression $ y = 5x - 7 $.  \nPlug in $ x = 2 $:  \n$$\ny = 5(2) - 7 = 10 - 7 = 3\n$$\n\n**Final Answer:**  \n$$\nx = 2,\\quad y = 3\n$$\n\n---\n\n### Verification via Elimination Method:\n\n**Step 1:** Multiply Equation 1 by 5 and Equation 2 by 2 to align coefficients of $ x $.  \n$$\n\\begin{aligned}\n&5(2x + 3y) = 5(13) \\Rightarrow 10x + 15y = 65 \\quad \\text{(Equation A)} \\\\\n&2(5x - y) = 2(7) \\Rightarrow 10x - 2y = 14 \\quad \\text{(Equation B)}\n\\end{aligned}\n$$\n\n**Step 2:** Subtract Equation B from Equation A to eliminate $ x $.  \n$$\n(10x + 15y) - (10x - 2y) = 65 - 14\n$$  \nSimplify:  \n$$\n17y = 51\n$$  \nDivide by 17:  \n$$\ny = 3\n$$\n\n**Step 3:** Substitute $ y = 3 $ into Equation 2 to find $ x $.  \n$$\n5x - 3 = 7 \\Rightarrow 5x = 10 \\Rightarrow x = 2\n$$\n\n**Verification:**  \nCheck in both original equations:  \n- For $ x = 2 $, $ y = 3$:  \n  $$2(2) + 3(3) = 4 + 9 = 13 \\quad (\\checkmark)$$  \n  $$5(2) - 3 = 10 - 3 = 7 \\quad (\\checkmark)$$\n\nThus, the solution to the system is confirmed as **$(2, 3)$**. \n\n**Answer:**  \n$$\n(x, y) = \\boxed{(2, 3)}\n$$"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure generation parameters\n",
        "generation_config = {\n",
        "    \"max_new_tokens\": 2000,\n",
        "    \"temperature\": 0.2,\n",
        "    \"do_sample\": True,\n",
        "    \"top_p\": 0.9,\n",
        "    \"repetition_penalty\": 1.1,\n",
        "    \"return_full_text\": False\n",
        "}\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"name\": \"solve_linear_system\",\n",
        "        \"description\": \"Solve a system of linear equations Ax = b using numpy.linalg\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"coeff_matrix\": {\n",
        "                    \"type\": \"array\",\n",
        "                    \"items\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\"type\": \"number\"}\n",
        "                    },\n",
        "                    \"description\": \"Coefficient matrix A\"\n",
        "                },\n",
        "                \"rhs_vector\": {\n",
        "                    \"type\": \"array\",\n",
        "                    \"items\": {\"type\": \"number\"},\n",
        "                    \"description\": \"Right-hand side vector b\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"coeff_matrix\", \"rhs_vector\"]\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "def solve_linear_system(coeff_matrix, rhs_vector):\n",
        "    import numpy as np\n",
        "    A = np.array(coeff_matrix, dtype=float)\n",
        "    b = np.array(rhs_vector, dtype=float)\n",
        "    sol = np.linalg.solve(A, b)\n",
        "    return {\"solution\": sol.tolist()}\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that should use tools where possible.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Solve the system of linear equations: 2x + 3y = 13, 5x - y = 7\"}\n",
        "]\n",
        "\n",
        "# Apply chat template\n",
        "formatted_with_tools = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    xml_tools=tools,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "raw_output = pipe(formatted_with_tools, **generation_config)[0][\"generated_text\"]\n",
        "\n",
        "try:\n",
        "    start = raw_output.rfind(\"<tool_call>\") + len(\"<tool_call>\")\n",
        "    end = raw_output.rfind(\"</tool_call>\")\n",
        "    print (\"raw_output = \", raw_output[start:end], \"\\n\")\n",
        "    tool_call = json.loads(raw_output[start:end])\n",
        "    tool_name = tool_call[\"name\"]\n",
        "    args = tool_call[\"arguments\"]\n",
        "    print (\"tool_call == \", tool_call)\n",
        "\n",
        "    if tool_name == \"solve_linear_system\":\n",
        "        tool_result = solve_linear_system(**args)\n",
        "        print (\"tool_result = \", tool_result, \"\\n\")\n",
        "        messages.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": raw_output,\n",
        "            \"tool_calls\": [tool_call]\n",
        "        })\n",
        "        messages.append({\n",
        "            \"role\": \"tool\",\n",
        "            \"tool_call_id\": tool_name,\n",
        "            \"content\": json.dumps(tool_result)\n",
        "        })\n",
        "\n",
        "        formatted_chat = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            xml_tools=tools,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "        final_output = pipe(formatted_chat, **generation_config)[0][\"generated_text\"]\n",
        "        display(Markdown(final_output))\n",
        "except Exception as e:\n",
        "    print(\"No tool call found:\", e)\n",
        "    display(Markdown(raw_output))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "rEBvr-ha5-vj",
        "outputId": "c20f82a2-f603-409a-f1e3-98b27cdfd3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raw_output =  \n",
            "{\"name\": \"solve_linear_system\", \"arguments\": {\"coeff_matrix\": [[2, 3], [5, -1]], \"rhs_vector\": [13, 7]}}\n",
            " \n",
            "\n",
            "tool_call ==  {'name': 'solve_linear_system', 'arguments': {'coeff_matrix': [[2, 3], [5, -1]], 'rhs_vector': [13, 7]}}\n",
            "tool_result =  {'solution': [2.0, 3.0]} \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<think>\n\n</think>\nThe solution to the system of linear equations is x = 2.0 and y = 3.0. \n\nHere's how we used the `solve_linear_system` tool for this task:\n\nWe called the `solve_linear_system` function with the coefficient matrix `[[2, 3], [5, -1]]` representing our equations' coefficients and the right-hand side vector `[13, 7]`. The result was returned as a list containing the solutions for x and y, which were calculated to be approximately 2.0 and 3.0 respectively. This confirms that (2, 3) satisfies both original equations."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_notebook(filepath):\n",
        "    try:\n",
        "        filepath = os.path.abspath(filepath)\n",
        "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "            notebook = json.load(f)\n",
        "\n",
        "        modified = False\n",
        "        if \"metadata\" in notebook and \"widgets\" in notebook[\"metadata\"]:\n",
        "            del notebook[\"metadata\"][\"widgets\"]\n",
        "            modified = True\n",
        "\n",
        "        if modified:\n",
        "            with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump(notebook, f, indent=2)\n",
        "            print(f\"Cleaned {filepath}\")\n",
        "            return True\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {filepath}: {str(e)}\", file=sys.stderr)\n",
        "        return False\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "cEBQv1O5-cNi",
        "outputId": "6a164146-f3b9-464a-a185-066c203bc160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot convert notebook to v5 because that version doesn't exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2462262992.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Step 1: open the notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ✅ as_version is int 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Step 2: fix missing widget 'state' in metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nbformat/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(fp, as_version, capture_validation_error, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_validation_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_validation_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nbformat/__init__.py\u001b[0m in \u001b[0;36mreads\u001b[0;34m(s, as_version, capture_validation_error, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mas_version\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNO_CONVERT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nbformat/converter.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(nb, to_version)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Recursively convert until target version is reached.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;34m\"Cannot convert notebook to v%d because that version doesn't exist\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot convert notebook to v5 because that version doesn't exist"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print current notebook path\n",
        "!ls /content/drive/MyDrive/Colab\\ Notebooks/chat-templates.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BU3Pbrr3E3kc",
        "outputId": "02f69def-44b0-4d8e-ee69-7a4bc622aca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/Colab Notebooks/chat-templates.ipynb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1d0btycEcEq",
        "outputId": "e30ba501-f03c-4d5c-c093-0cc75dca1159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "lJbkwPmp1Wo_"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}