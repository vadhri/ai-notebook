{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venkat/opt/anaconda3/envs/llm/lib/python3.12/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.25) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Day 1:\n",
      "Warm-up: Light jog for 5 minutes\n",
      "\n",
      "Circuit 1:\n",
      "1. 30 second sprints\n",
      "2. 1 minute easy jog\n",
      "3. 30 second high knees\n",
      "4. 1 minute easy jog\n",
      "Repeat circuit 3 times\n",
      "\n",
      "Circuit 2:\n",
      "1. 1 minute mountain climbers\n",
      "2. 1 minute jump squats\n",
      "3. 1 minute burpees\n",
      "4. 1 minute rest\n",
      "Repeat circuit 3 times\n",
      "\n",
      "Cool down: 10 minute brisk walk\n",
      "\n",
      "Day 2:\n",
      "Warm-up: 5 minute jog\n",
      "\n",
      "Circuit 1:\n",
      "1. 5 minute fast paced run\n",
      "2. 1 minute rest\n",
      "3. 3 minute run uphill\n",
      "4. 1 minute rest\n",
      "Repeat circuit 3 times\n",
      "\n",
      "Circuit 2:\n",
      "1. 20 minute bike ride\n",
      "2. 1 minute rest\n",
      "3. 10 minute run\n",
      "4. 1 minute rest\n",
      "Repeat circuit 2 times\n",
      "\n",
      "Cool down: 5 minute slow jog\n",
      "\n",
      "Day 3:\n",
      "Warm-up: 5 minute jog\n",
      "\n",
      "Circuit 1:\n",
      "1. 1 minute jogging in place\n",
      "2. 1 minute high knees\n",
      "3. 1 minute jump rope\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0.9)\n",
    "\n",
    "text = \"Suggest a personalized workout routine for someone looking to improve cardiovascular endurance and prefers outdoor activities.\"\n",
    "print(llm(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Some popular Indian companies that produce mobile phones are:\n",
      "1. Xiaomi\n",
      "2. Samsung\n",
      "3. Realme\n",
      "4. Oppo\n",
      "5. Vivo\n",
      "6. Micromax\n",
      "7. Lava\n",
      "8. Karbonn\n",
      "9. Intex\n",
      "10. Jio Phone (Reliance Jio)\n"
     ]
    }
   ],
   "source": [
    "# LLM chain = PromptTemplate + a model + an optional output parser. \n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0.9)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"], \n",
    "    template=\"What is the indian company that makes {product} ?\"\n",
    "    )\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "print(chain.run(\"mobile phones\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: I have 20 ruppees with me.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: I have 20 ruppees with me.\n",
      "AI:  That's great! Did you know that the ruppee is the official currency of India? It was first introduced in 1540 by the Afghan ruler Sher Shah Suri. Today, it is used in India, Nepal, and Bhutan. 20 ruppees may not seem like a lot, but it can buy you a cup of chai tea or a plate of samosas in India. Do you have any plans for your ruppees?\n",
      "Human: The shop has water bottles 10 ruppees each\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: I have 20 ruppees with me.\n",
      "AI:  That's great! Did you know that the ruppee is the official currency of India? It was first introduced in 1540 by the Afghan ruler Sher Shah Suri. Today, it is used in India, Nepal, and Bhutan. 20 ruppees may not seem like a lot, but it can buy you a cup of chai tea or a plate of samosas in India. Do you have any plans for your ruppees?\n",
      "Human: The shop has water bottles 10 ruppees each\n",
      "AI:  That's a good deal! Did you know that the average price of a bottle of water in India is around 20 ruppees? However, prices can vary depending on the brand and location. It's always a good idea to stay hydrated, especially in a warm country like India. Will you be purchasing any water bottles with your ruppees?\n",
      "Human: How many water bottles can i buy ?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" With 20 ruppees, you can buy two water bottles at the price of 10 ruppees each. However, if you want to save some ruppees, you can also refill your water bottle at a public water station for free. It's a more environmentally friendly option too!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt memory = model + conversation chain \n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "conv = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    memory=ConversationBufferMemory()\n",
    "    )\n",
    "\n",
    "conv.predict(input=\"I have 20 ruppees with me.\")\n",
    "conv.predict(input=\"The shop has water bottles 10 ruppees each\")\n",
    "conv.predict(input=\"How many water bottles can i buy ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval QA from deeplake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 1 embeddings in 1 batches of size 1:: 100%|██████████| 1/1 [00:42<00:00, 42.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://test-venkat/planets', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      "   text       text      (1, 1)      str     None   \n",
      " metadata     json      (1, 1)      str     None   \n",
      " embedding  embedding  (1, 1536)  float32   None   \n",
      "    id        text      (1, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['dd9c20f6-e71e-11ee-8f7d-f21898795428']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "import os \n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "lines = []\n",
    "with open(\"planet.txt\", \"r\") as f:\n",
    "    lines.append(f.readline())\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.create_documents(lines)\n",
    "\n",
    "my_activeloop_org_id = \"test-venkat\" \n",
    "my_activeloop_dataset_name = \"planets\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "\n",
    "# add documents to our Deep Lake dataset\n",
    "db.add_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "\tllm=llm,\n",
    "\tchain_type=\"stuff\",\n",
    "\tretriever=db.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Retrieval QA System\",\n",
    "        func=retrieval_qa.run,\n",
    "        description=\"Useful for answering questions.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "\ttools,\n",
    "\tllm,\n",
    "\tagent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "\tverbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the Retrieval QA System to find the answer.\n",
      "Action: Retrieval QA System\n",
      "Action Input: \"What is Celestoria Prime?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Celestoria Prime is a fictitious planet located in the Gemini Cluster on the fringes of the galactic expanse. It is known for its unique features, diverse ecosystems, and a thriving civilization that lives in harmony with the planet's natural wonders.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Celestoria Prime is a fictitious planet located in the Gemini Cluster.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Celestoria Prime is a fictitious planet located in the Gemini Cluster.\n"
     ]
    }
   ],
   "source": [
    "response = agent.run(\"what is Celestoria Prime?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few shot template\n",
    "Generalize answers from a list of templates.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well, that depends on your preferences! If you enjoy breathtaking natural beauty, diverse ecosystems, and a harmonious civilization, then Celestoria Prime might be the perfect place for you. Just make sure to pack your space suit and prepare for a cosmic adventure!'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "# examples \n",
    "prefix = \"\"\"Celestoria Prime, a celestial marvel nestled in the cosmic tapestry, \n",
    "    orbits a distant star in the Gemini Cluster, located on the fringes of the galactic \n",
    "    expanse. This fictitious planet is a testament to the wonders that can emerge in \n",
    "    the vastness of the cosmos, boasting a plethora of unique features, diverse ecosystems, \n",
    "    and a civilization that thrives in harmony with the planet's natural splendors. \n",
    "    The following are excerpts from conversations with an AI\n",
    "    assistant. The assistant is known for its humor and wit, providing\n",
    "    entertaining and amusing responses to users' questions. Here are some\n",
    "    examples:\n",
    "    \"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"query\": \"what are the physical characteristics of Celestoria Prime?\",\n",
    "        \"answer\": \"\"\"Celestoria Prime is a rocky terrestrial planet with a diameter approximately 1.5 times that of Earth. Its surface is adorned with sprawling landscapes, majestic mountain ranges, and vast expanses of crystalline lakes that shimmer under the warm embrace of the system's sun, Luminary Helios. The planet's gravity is slightly stronger than Earth's, providing a sense of solidity to its terrain.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"\"\"Describe the biodiversity of Celestoria Prime\"\"\",\n",
    "        \"answer\": \"\"\"Celestoria Prime boasts an astonishing biodiversity, with over 500,000 documented species of flora and fauna. Conservation efforts are integral to Celestrian culture, ensuring the preservation of the planet's unique ecosystems.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "promptTemplate = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "examplePrompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=promptTemplate\n",
    ")\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=data,\n",
    "    example_prompt=examplePrompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import LLMChain\n",
    "\n",
    "# load the model\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "chain = LLMChain(llm=chat, prompt=few_shot_prompt_template)\n",
    "chain.run(\"Should i move to planet celestoria prime ?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
