{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c8b52ff1-561d-4c96-9a4f-f6873bef244e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6308,  0.0204],\n",
       "        [-1.0404, -0.7600],\n",
       "        [ 0.8160, -0.3312],\n",
       "        [ 0.9665, -1.7312],\n",
       "        [-0.3889, -0.6368],\n",
       "        [-0.1730,  0.1489],\n",
       "        [-0.6770, -0.3378],\n",
       "        [-1.1074, -0.1256]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "batches, block_size, channels = 4,8,2\n",
    "\n",
    "x = torch.randn(batches, block_size, channels)\n",
    "x[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a559a6-6799-4628-bb60-93aea648b779",
   "metadata": {},
   "source": [
    "The tokens should flow from the previous context to the future tokens. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e38569-de66-466a-99dc-dcb74ba43245",
   "metadata": {},
   "source": [
    "## Averaging\n",
    "All previous tokens up until token t will be averaged. There will be considerable information loss in this process. \n",
    "\n",
    "$ X_{b,t} = \\frac{1}{T} \\sum_{i=0}^T X_{b,i} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4fdf8fe7-7c98-4bcf-b155-042808e34d11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.6308,  0.0204],\n",
       "         [-0.2048, -0.3698],\n",
       "         [ 0.1355, -0.3569],\n",
       "         [ 0.3432, -0.7005],\n",
       "         [ 0.1968, -0.6878],\n",
       "         [ 0.1352, -0.5483],\n",
       "         [ 0.0192, -0.5182],\n",
       "         [-0.1217, -0.4692]]),\n",
       " tensor([[ 0.6308,  0.0204],\n",
       "         [-1.0404, -0.7600],\n",
       "         [ 0.8160, -0.3312],\n",
       "         [ 0.9665, -1.7312],\n",
       "         [-0.3889, -0.6368],\n",
       "         [-0.1730,  0.1489],\n",
       "         [-0.6770, -0.3378],\n",
       "         [-1.1074, -0.1256]]),\n",
       " -0.74855)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow = torch.zeros((batches,block_size,channels))\n",
    "for batch in range(batches):\n",
    "    for block in range(block_size):\n",
    "        xprev = x[batch,:block+1]\n",
    "        xbow[batch,block] = torch.mean(xprev,0)\n",
    "        \n",
    "xbow[0], x[0], (-1.1870-0.3101)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2173a3-3204-4e20-a824-19366a4d62b0",
   "metadata": {},
   "source": [
    "In order to get the same result, we can use matrix multiplication using the lower triangle matrix and then calculating average for each rowxcol multiplication.\n",
    "\n",
    "### Torch method - tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7af148d0-d462-41d7-83ee-2264228a64fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.tril(torch.ones(block_size,block_size))\n",
    "weights = weights / weights.sum(1, keepdim=True)\n",
    "\n",
    "print (weights)\n",
    "\n",
    "xbow2 = weights @ x\n",
    "\n",
    "torch.allclose(xbow2, xbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32da83ab-e3c3-4dad-a97b-06fb8fbae4c7",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2e034c7-aa40-4e2d-a999-c0800b1efa9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(block_size, block_size))\n",
    "weights = torch.zeros((block_size, block_size))\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "print(weights)\n",
    "\n",
    "xbow2 = weights @ x\n",
    "\n",
    "torch.allclose(xbow2, xbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ea2338-be59-46f9-b728-a1fafe29a422",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data dependent self-attention head\n",
    "\n",
    "This section shows an example of scaled dot-product attention sample from the 3.2.1 of paper (attn is all you need !). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7a8a5f1b-2986-4e0a-82a4-2af7dd27517a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.7700, 0.2300, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.5087, 0.2784, 0.2129, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2172, 0.2747, 0.1749, 0.3331, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1902, 0.1937, 0.1839, 0.2478, 0.1843, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1083, 0.2550, 0.1970, 0.1581, 0.2000, 0.0815, 0.0000, 0.0000],\n",
      "         [0.1058, 0.1034, 0.0718, 0.1642, 0.1555, 0.2547, 0.1446, 0.0000],\n",
      "         [0.1171, 0.1342, 0.2769, 0.0855, 0.1072, 0.0905, 0.1322, 0.0564]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3494, 0.6506, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3506, 0.3445, 0.3049, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2934, 0.2030, 0.2560, 0.2476, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2679, 0.1502, 0.2152, 0.1830, 0.1836, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1583, 0.1833, 0.1142, 0.1949, 0.1752, 0.1740, 0.0000, 0.0000],\n",
      "         [0.1963, 0.1138, 0.1117, 0.2105, 0.0669, 0.1833, 0.1175, 0.0000],\n",
      "         [0.1047, 0.1700, 0.1194, 0.1082, 0.1657, 0.0968, 0.1497, 0.0855]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.6792, 0.3208, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2654, 0.4650, 0.2696, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1470, 0.1919, 0.3404, 0.3206, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1416, 0.1994, 0.2102, 0.1826, 0.2662, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2633, 0.2105, 0.1169, 0.0899, 0.1784, 0.1410, 0.0000, 0.0000],\n",
      "         [0.1694, 0.1325, 0.2070, 0.1394, 0.1615, 0.0700, 0.1201, 0.0000],\n",
      "         [0.1317, 0.1298, 0.1368, 0.1242, 0.0853, 0.1512, 0.1214, 0.1196]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3210, 0.6790, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4241, 0.3200, 0.2559, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4221, 0.1592, 0.1611, 0.2577, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4388, 0.1381, 0.1716, 0.1109, 0.1405, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1302, 0.2348, 0.1024, 0.1566, 0.2425, 0.1336, 0.0000, 0.0000],\n",
      "         [0.1174, 0.1511, 0.1448, 0.1245, 0.1291, 0.1686, 0.1646, 0.0000],\n",
      "         [0.0582, 0.1183, 0.1608, 0.0677, 0.1545, 0.1263, 0.1845, 0.1298]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batches, block_size, no_of_embeddings = 4,8,32\n",
    "attn_head_size = 16\n",
    "\n",
    "test = torch.randn(batches, block_size, no_of_embeddings)\n",
    "\n",
    "key = nn.Linear(no_of_embeddings, attn_head_size, bias=False)\n",
    "query = nn.Linear(no_of_embeddings, attn_head_size, bias=False)\n",
    "value = nn.Linear(no_of_embeddings, attn_head_size, bias=False)\n",
    "\n",
    "k = key(test) # batches x blocksize x attn_head_size\n",
    "q = query(test) # batches x blocksize x attn_head_size\n",
    "v = value(test)\n",
    "\n",
    "# Normalize to ensure that the softmax does not eventually starts converging the max values into 1. \n",
    "weights = q @ k.transpose(-2, -1) * attn_head_size**-0.5 # Multiply only last two dimensions above \n",
    "\n",
    "# The above operation mulitplies the following. \n",
    "# q ( batches, block_size, attn_head_size ) x k( batches, attn_head_size, block_size)\n",
    "# result = batches x block_size x block_size\n",
    "\n",
    "tril = torch.tril(torch.ones(block_size, block_size))\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "print (weights)\n",
    "\n",
    "xbow2 = weights @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7cf94b-bd51-4358-b529-142ea17d3c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
