{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vadhri/ai-notebook/blob/main/audio/asr_model_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcgZOcrSTyl-",
        "outputId": "b9102e48-9af6-47f9-add7-cea4532a17d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U datasets\n",
        "!pip install -q -U gradio\n",
        "!pip install -q -U accelerate\n",
        "!pip install -q -U evaluate\n",
        "!pip install -q -U jiwer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "b1ce895c5b7241999e3c78a39c29c60f",
            "8d3910c2719c450a96d9a607784d2f81",
            "4618ba23fea544b18fa164d2f59df1d5",
            "8fa0c630af3945509e1a6e784b93d822",
            "996cbb5dd4444273bea641b6a994a8ba",
            "286169a2e16f4c038695aaf12fd77106",
            "a4e3578f4d2349089245e39db3a2a836",
            "8c55d8f8f619461ea3c5700e62b27e2f",
            "3efed9620b4c44109295c2b8467d9aac",
            "0f30039e749041c6ada0ee2b60a5bcf7",
            "d93cc8ed7ae144689e0fe216b3ed90fc",
            "f3029e23424e498d8491bb518e02d255",
            "7e8caf4071b24fd2bd1e329b2e92a274",
            "5e69cdb4e39d4de8ae2212a7c07bb0d0",
            "f73fde1211d144fcae0c5caaab129fae",
            "ef0f0620fad94466b3e906e94fcbc26f",
            "296e1fe954fb424982e3ff829d306ab4",
            "6f386031827f48a99b9b00c928291017",
            "a72024b036b74493ad4a79cc6d0e625e",
            "77d16f325e83403bab4d9d5f49552929",
            "b8d73888384f467b8946d8c0d0b1e48e",
            "2607c04dd84e47409588b25817e0644d",
            "54e3ddcb47a144dda3618c0a6bec4986",
            "9f4b7d51c5084f338f3fd9ecb23fafe8",
            "ff46bbc2526c4b0e8d759eb422749a9b",
            "c9a3cc9b4cff48328560601d50136029",
            "9190bad6e794400c9e784f616cc256b8",
            "5a9e3917d5de475aafce18f592e1cf12",
            "931617c73ac4431583792298b7979f55",
            "d9021a51ad354436a301fa88545f4adb",
            "54e38e7a9ee04172ac6b18303d23b79b",
            "a3128aa6b7fa4996ace65fb90cc61265"
          ]
        },
        "id": "ZauQoycezD5p",
        "outputId": "ec65ccb4-3f22-4e62-9212-22fcf51ff307"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1ce895c5b7241999e3c78a39c29c60f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512,
          "referenced_widgets": [
            "0dfbb7593c764e59b0b5e38233f31295",
            "aa54f9c9e77b496c8a80007156e3cc20",
            "e107f125fc7548cc8796b4c1b778c666",
            "54e94e42f52e41f9ae16ab4f015accc0",
            "729899fae5b843d5b4941cac6dc4fec9",
            "cdadb2608b71429da6566f53ef364aca",
            "7d2e5eeb6bc24556a86b5d4a115e19a5",
            "9bdb8a9e57ba4bf2b9e9f1dd955bfbd2",
            "869fea65e61240b980c064aa113a648d",
            "08a83a391f4a4fd9abf4a97c54fb7f1b",
            "24017e7f4ae74d7486877e65c7349c5a",
            "0efa36d2357b47bba797f71b5746a801",
            "17356e7ef144474eb5dda052c391b6e4",
            "59a3cb8e268e4e44b33c25637e0843a4",
            "cd085b6636314f158b94a41a5770751c",
            "7a7e8571bbaa414f85f196c4ad3829b1",
            "48b9431d0a7242b5853270d312677da1",
            "2fda4b54e7e5449389febb858b6fe5cd",
            "6b8b999fa29045b4b218473bb3351f96",
            "bd6778767125475d95459ec98cd54fc6",
            "d5b12b61de8d4f2a91f319ac28a6f742",
            "9c2f765c1dd1484da167174f1224f97f",
            "01c9048e9dcb4303bc6627c574f59665",
            "0132843120c64a749ef2daf1f1a80adc",
            "f37e3f7a029b47ce89233ffdca992ad3",
            "e0cea3a6748c446c8c338f8aec973eb3",
            "bea7bdbfd31c497ba8379ae603a74f93",
            "fd43c957886e4622b06df04b57279bd3",
            "c554e0b4d92c4725b1f81c73930ccce6",
            "6ea64934f9724b11a3dd13295cd122bd",
            "78154aa81cc649cd86577f939ba0b531",
            "e993d38c2f2a477fb32b43d1fe3a1018",
            "115a7a9b93164cdbae5a35dd5a9912e1",
            "39f7a8f7fca741d88fce89269d595185",
            "1898f67762454c66982deac8cc645889",
            "3bf43dd17dc84fa887a14e4b3c77aee2",
            "133856b71cac416caffd8a56bddca384",
            "4e76165e28fd48b8927d75b39d39e2e8",
            "fc5e488413c7400a89231127407007ad",
            "fe4fcd46963044b696d6e3058d345296",
            "ab7cdda17f2840a0a3574eb4f70cbab7",
            "cb1a3cc836964c08a5a0a7f338c00fa4",
            "83cd55134a2e4b1f9c3c1e4acb13563e",
            "1fa894cf42884a87a6deec92f9856d6d"
          ]
        },
        "id": "lAUaJZ2nTpi2",
        "outputId": "fa666d02-dda9-4963-f7ef-ff56ec4c8069"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1486: FutureWarning: The repository for PolyAI/minds14 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/PolyAI/minds14\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0dfbb7593c764e59b0b5e38233f31295",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.90k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0efa36d2357b47bba797f71b5746a801",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/5.29k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01c9048e9dcb4303bc6627c574f59665",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/471M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39f7a8f7fca741d88fce89269d595185",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
              "        num_rows: 450\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
              "        num_rows: 113\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "common_voice = DatasetDict()\n",
        "\n",
        "common_voice = load_dataset(\"PolyAI/minds14\", \"en-US\", split=\"train\")\n",
        "common_voice = common_voice.train_test_split(test_size=0.2)\n",
        "common_voice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBOgOqfIT8Ry"
      },
      "outputs": [],
      "source": [
        "common_voice = common_voice.select_columns([\"audio\", \"transcription\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290,
          "referenced_widgets": [
            "d1685be3f58343bf8d1b9fe512150822",
            "5a9ec4d5147942ceb65741aa4f897477",
            "837c1d0ed56d47c9b65b6b24a7937bf9",
            "aa66893852c5400f987a536d5697618a",
            "21283b2d939f491ab3cfb378bf33f24d",
            "88c2520e74ba4e7d8ba33d86b1d97ca4",
            "b93502f7277048c0960b0c12f563def4",
            "298bb1c78dee45408d989bb7c20a10f4",
            "cf5e27f0343f464fba15654db35db17e",
            "fd2506d7a18f47d6a51664e195ee4f6d",
            "923a2fd12c2b48168df4d069f9c725cf",
            "847e41d43e5043659429635172786de8",
            "04fd87f5ff0a432d9ef0a5c360057d8e",
            "e7d68c83720740bdbfda6d9904526e52",
            "48161b909fdc431dbbfd9ec1c3bd2062",
            "bddcdca6aab24fdf83d5c830c983ddf8",
            "792d76c216bf4f388acef525c1283144",
            "c6b9ea8555e046679d1ab820cb979a22",
            "dc18c7d0964c44ad8f9298a23e94eff8",
            "3c726d187b0e424e8795921cc6d82699",
            "f8fb1fe7a61d4f19b116ddfaa1913d6b",
            "8f69e6ba7af6459c8c612b5bc4d26aa5",
            "9544ed586ad645bfb52d21a4ca9e14aa",
            "b681ae6178f945ab93010e2cd65ff1ef",
            "fe79e5d43c2540569c292811a90d2ee6",
            "27ff942eccfd4a89a1f94e1986096311",
            "f53bbd01c61c490b9698784f48b371da",
            "40caf17111a94363828954ed919db891",
            "9569a98085774445a7e0442212ccfae6",
            "4fbaad3d8cb64b27b3a4fe5e5f2e6fde",
            "374d1fbb0d674fca915fdd06ae043ef7",
            "17d349b2fd15486aaff78e6984038e3d",
            "b69fc3dc90774bdf9329c1fc604d1a22",
            "4cce80f2a23d4edd9dded11cb703a50f",
            "9fea87520f5d48fb9c40546b8afd54ec",
            "015a24acdb3e454f87d30299c593e037",
            "a283240254e04a3eb1319ecd0c6a57e1",
            "bf7b988dd7304801aaf5fc34e6826785",
            "e20332abcb2d4e16829e704f74289cd8",
            "22c6890cb37145eb9917a7cea0b789c2",
            "d7c42f64f0d94e54842da1fb7e1a9f03",
            "5396efeebbb24134a398eec7331be421",
            "932659b929f94cbf84a6f05713759190",
            "31ba3f578f0b45a181fa5ca3138085a8",
            "61db11cc6d684508b338702d787f68b2",
            "2183fe9bec2645bf8ddf7019fa1086ac",
            "44c3200afcd543cab16504b020b0c07a",
            "58ae2384650744b59ccf0913627698df",
            "a29d167a259844388813eeaa51acd2a4",
            "82fcc19070f84755a8d7e0ae1cff39c8",
            "9615931d4f3b4410af2f0fc0a79b8fbf",
            "9b44fb1e094b41139cda4de76d9dc624",
            "71c2acba33f347b68b6a06eca0025409",
            "0b827ea4629746c189f803a47ff2a51f",
            "e442e2c75154458cae665b008c9dff53",
            "4e3ccb00626a4184a539755d5529413c",
            "33083b04b33240e9b74ff29529a90731",
            "a8391a17ea104220b839201cf1303b77",
            "6a87d4b6a8934878a370e22131570019",
            "ce1f3ef319504200bac7b1f2760cd1d4",
            "67e2cdb69af2419e92a5bd50ea074c81",
            "de1855db322a4fa69d1eb8111f3defa7",
            "5728a4bba79c492d8642f079b0380b45",
            "4b269682f2864b2292b09b04c9d04d06",
            "3561cd787c094f8b9c702ecc355d5ac8",
            "e7dfeb24ab7d41419a03faa4b425f87a",
            "bfb546162b8d4ff28fcbde98c71875b9",
            "aef171f328ec4259a1cacbf209160fcc",
            "79600b94d0cf4c67b00f3d6e6b88c8e9",
            "b9ff909c05ab46d2a9cab5b7c2bceed1",
            "4fd0780b67af4b268ac04740935522ac",
            "0c46cf2db4d3402d9dcb6bb8c75de6e3",
            "42a53f1a6ccd49cda27face1cc2bbecd",
            "265184aafa4840899d0e043e3253251f",
            "86200933d2194604b2784b7c22501252",
            "07ef7fe648ed4909a3eca04b80634eba",
            "76cb43c32f14482bb4f7bf51c2b3090e",
            "0bd826a89d594969a214d817d28cbab7",
            "b294d8d3825f4279b50f3d0352dd7c55",
            "89acd84fdeb648c6afc11caf0c218daa",
            "28d4236b1134484c9ed29bfb411b52f8",
            "89c87c723bfb4547a79410ff907a80b7",
            "180bb1d0f45e4b4e83b0e6fbd7d38ede",
            "b8b356e24e31469c98daefd9155e7c7d",
            "bbfa281992ec4c2aa4c2eaa911fb1a0c",
            "96160f7d5e7444a0801c98ff2f84cc81",
            "d52ccc7471874134b356a0ccc1dc5651",
            "f258404a31fc4e3d96bf91ff34beca66"
          ]
        },
        "id": "96ikirh4UJz0",
        "outputId": "cc881a4f-b5bb-4b9d-b77f-d1744f223b4e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1685be3f58343bf8d1b9fe512150822",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "847e41d43e5043659429635172786de8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9544ed586ad645bfb52d21a4ca9e14aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cce80f2a23d4edd9dded11cb703a50f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61db11cc6d684508b338702d787f68b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e3ccb00626a4184a539755d5529413c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfb546162b8d4ff28fcbde98c71875b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bd826a89d594969a214d817d28cbab7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import WhisperProcessor\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\n",
        "    \"openai/whisper-tiny\", language=\"english\", task=\"transcribe\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0jE7r0c3L2b",
        "outputId": "068c7e2f-be48-4294-955f-244b7dcf1adb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampling rate =  16000\n"
          ]
        }
      ],
      "source": [
        "from datasets import Audio\n",
        "\n",
        "sampling_rate = processor.feature_extractor.sampling_rate\n",
        "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))\n",
        "print (\"Sampling rate = \", sampling_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtuTG7IX3PH4"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(example):\n",
        "    audio = example[\"audio\"]\n",
        "\n",
        "    example = processor(\n",
        "        audio=audio[\"array\"],\n",
        "        sampling_rate=audio[\"sampling_rate\"],\n",
        "        text=example[\"transcription\"],\n",
        "    )\n",
        "\n",
        "    # compute input length of audio sample in seconds\n",
        "    example[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n",
        "\n",
        "    return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "836fd6f51a3b4369b8eb2c108dfb7afd",
            "eba1ee6bdb684a8eb00596785cc5d88b",
            "01d9f3a2ad3b480b8e85843af0dd7c05",
            "0420361e44f94b158a109234585be628",
            "d440814d5f524c0e8ac744c8375f7608",
            "dfe63daf252240d2a1473ff542af982b",
            "8df7d2b85649435f9a645b462a25e78d",
            "165f52be8ba04a818f12585c35caeb9b",
            "1aefbcdcb52540eaac96aac691e21f29",
            "3b50d52554dc43c29f5b387583a917e1",
            "ce93c4cb8da3412c9fdde3b6fe13e9c0",
            "4a989f25a0384b9fbdcf12c387a9ab7e",
            "30bfc061559f47958dce8978617b0544",
            "054c829c1ee04e85b09649c567780691",
            "89dcfd756e174925b82eb3af0c345be2",
            "63f3c2a4803a403e912f68043e0811fc",
            "02d7544b65964c35bf77386a94326d9d",
            "e0f70519b57b458184f4f0979878d603",
            "d818b209e7c84f5cac9bd5ee69e0a4e3",
            "ea3e738c404f48f98a4d2922df04ae04",
            "e380c02706e3438a8ba489c598337f11",
            "fe77de8602fc4af3856c38a04edf0825"
          ]
        },
        "id": "tTDb01zd3RbD",
        "outputId": "cc02dde4-749e-4563-92cf-694faa34e21a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "836fd6f51a3b4369b8eb2c108dfb7afd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/450 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a989f25a0384b9fbdcf12c387a9ab7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/113 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "common_voice = common_voice.map(\n",
        "    prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c2a7f106a1ef4edd9804ff77dc93b3b3",
            "86244ce61636486792fb77ed5fcd4810",
            "9641eb65192a4158a989674edc66c356",
            "146252af09c4424ea231404538214678",
            "794658e9913e4fb79ae211c7d823e13a",
            "4881292e6a4f43c28fa86e2fa3feaa19",
            "261baf3411e94d9f842b718a4c159c38",
            "c683e7e677da4a378232998cf8674adc",
            "d4271892b964497cb6f7f44ea0200ece",
            "3e1eb7575f104ba8bb0dc02c6c526acc",
            "b46ad624842f4f32b7c4ca6bb65a7a87"
          ]
        },
        "id": "vB6TT1a33ThO",
        "outputId": "28ff8626-0957-4708-d84a-c7ac5901b7a5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2a7f106a1ef4edd9804ff77dc93b3b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/450 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "max_input_length = 30.0\n",
        "\n",
        "def is_audio_in_length_range(length):\n",
        "    return length < max_input_length\n",
        "\n",
        "common_voice[\"train\"] = common_voice[\"train\"].filter(\n",
        "    is_audio_in_length_range,\n",
        "    input_columns=[\"input_length\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ffi1d6JQ30mR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(\n",
        "        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]\n",
        "    ) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
        "        # first treat the audio inputs by simply returning torch tensors\n",
        "        input_features = [\n",
        "            {\"input_features\": feature[\"input_features\"][0]} for feature in features\n",
        "        ]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # get the tokenized label sequences\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        # pad the labels to max length\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
        "            labels_batch.attention_mask.ne(1), -100\n",
        "        )\n",
        "\n",
        "        # if bos token is appended in previous tokenization step,\n",
        "        # cut bos token here as it's append later anyways\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkIhqlCsl8vr"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e469be4cda2a4ff5ab75043b0b860ea0",
            "6d75c9f6ebda4839b65f2b0eb57e9b41",
            "b93169b6f2874dd0969b63be01060882",
            "d12342e1006a4582b41190bddc6e6fa8",
            "eca48278c6c2408782e4eb54a614af4a",
            "55ffbd58a78b429791df93999e3d116e",
            "9fd553bf3db34db08dc324599c246382",
            "e64c930b80874b3d80d759daa8e3ef5c",
            "796604da1d0e4cc6974f8732a5f5edb7",
            "a0b5d3f4a0d64e2f940d44f781a835a0",
            "85c6be866b604b42b19ac48b93090447"
          ]
        },
        "id": "9Ivc8H8t4hXO",
        "outputId": "49d2c3a6-956e-432b-9778-57d5e775da11"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e469be4cda2a4ff5ab75043b0b860ea0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"wer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efZppio2lmcE"
      },
      "outputs": [],
      "source": [
        "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
        "\n",
        "normalizer = BasicTextNormalizer()\n",
        "\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # replace -100 with the pad_token_id\n",
        "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "\n",
        "    # we do not want to group tokens when computing the metrics\n",
        "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    # compute orthographic wer\n",
        "    wer_ortho = metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    # compute normalised WER\n",
        "    pred_str_norm = [normalizer(pred) for pred in pred_str]\n",
        "    label_str_norm = [normalizer(label) for label in label_str]\n",
        "    # filtering step to only evaluate the samples that correspond to non-zero references:\n",
        "    pred_str_norm = [\n",
        "        pred_str_norm[i] for i in range(len(pred_str_norm)) if len(label_str_norm[i]) > 0\n",
        "    ]\n",
        "    label_str_norm = [\n",
        "        label_str_norm[i]\n",
        "        for i in range(len(label_str_norm))\n",
        "        if len(label_str_norm[i]) > 0\n",
        "    ]\n",
        "\n",
        "    wer = metric.compute(predictions=pred_str_norm, references=label_str_norm)\n",
        "\n",
        "    return {\"wer_ortho\": wer_ortho, \"wer\": wer}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "cd1153364c454d9c87cc2543ee3fb979",
            "e6b217efc775472e879a33f22fc71b99",
            "89a1dbb8c8c14f24bd612d52f6a73607",
            "d7781ecb8da049f3957efe792384fab9",
            "67dba9d8b82e4cc88adc2a3444c5f7a4",
            "c8e868374480480ca732d685822080b1",
            "b1dd7025ad8442ee8af9b955c717bb04",
            "8a11e2dca5544cb7acd47d3e89efdbdb",
            "b204173643af4af6b9e08fe6020822b3",
            "ee7bc4f19046417b90df968f4e968cbc",
            "f6ed01edb869418aa81027cbf45ff39a",
            "572d36d219464c3cb432b64de1ae6e28",
            "1c0c94feea394df88081c6f33dbc2033",
            "2c6c935ebec3447887e1ca16ddd79262",
            "1c4db0f32b78449c9348ac398aff725f",
            "987e22b7046c4d4fafcd3bf060046946",
            "9db81e15dcbd4fea8fe90c6a260c1542",
            "2bc539f7bde346f88cb1d6f2fa94d26b",
            "a4fbc3c877da4cefb6b62962ddf1a98d",
            "6d06309b461843609b17b8c6fda4cda2",
            "86464a7b672741178c6c3928d1bd0c9a",
            "f01c33f461de47bb8fc7dad719987872",
            "ef0c1d35fa9a42458200b715e3836856",
            "86ef2ca000364928a3ba9659ffc195c4",
            "43615aae6bdd46b6a44fdfd286bbfcc2",
            "e5a777f61a024b3ca8fb9bcec92accfb",
            "1ed6fbc76db6478fbfc9b94dcc3f432f",
            "19d6ab23e3f24ee7ab63a2e528ed255b",
            "1143d075d8084b75b0d57a07f044f386",
            "c0b18ec473ae48cab638e2f2f9157bc8",
            "08dce875a3d44e8981080096e14007e1",
            "f7061c36f83043ccbc1a19d81f584d69",
            "28ac1a9d9f3c40b2b64a8c0858d73f78"
          ]
        },
        "id": "KsLgSKcslqLI",
        "outputId": "9dbfabe9-fdc5-4849-cb68-1469f4ff64c6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd1153364c454d9c87cc2543ee3fb979",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.98k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "572d36d219464c3cb432b64de1ae6e28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/151M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef0c1d35fa9a42458200b715e3836856",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/3.75k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import WhisperForConditionalGeneration\n",
        "from functools import partial\n",
        "\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
        "model.config.use_cache = False\n",
        "model.generate = partial(\n",
        "    model.generate, language=\"english\", task=\"transcribe\", use_cache=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Td3OcP3plyNJ"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./whisper-tiny\",  # name on the HF Hub\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
        "    learning_rate=1e-5,\n",
        "    lr_scheduler_type=\"constant_with_warmup\",\n",
        "    warmup_steps=50,\n",
        "    max_steps=600,  # increase to 4000 if you have your own GPU or a Colab paid plan\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    fp16_full_eval=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_eval_batch_size=16,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    logging_steps=25,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"wer\",\n",
        "    greater_is_better=False,\n",
        "    push_to_hub=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vlsylyw2l1B1",
        "outputId": "1f0c6245-e55b-403e-91eb-aeb0d3a24d78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=common_voice[\"train\"],\n",
        "    eval_dataset=common_voice[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=processor,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ZWRBzjoXmDLY",
        "outputId": "24292bab-1f9f-418e-bda6-6bb382ef71e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 24:55, Epoch 21/22]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Wer Ortho</th>\n",
              "      <th>Wer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.678493</td>\n",
              "      <td>0.364433</td>\n",
              "      <td>0.356973</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=600, training_loss=0.23790589910155782, metrics={'train_runtime': 1502.6744, 'train_samples_per_second': 6.389, 'train_steps_per_second': 0.399, 'total_flos': 2.3582430056448e+17, 'train_loss': 0.23790589910155782, 'epoch': 21.43})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "9c2bc5ba548340e19824df5712caeb03",
            "00751af058ac481dbef5d74bf3f0ecaa",
            "5ba76a8df75a41dd845e3369c246509d",
            "645de3d163af41fcaf3d7a0c77a160b2",
            "304e364960054730a2d5743dae2c914e",
            "db5444f1eff0487cb178b914667e523b",
            "fd05fda8725542da8475e782ef923045",
            "cb02dcc1b9914720b7551f3d789d99de",
            "15c415c4270f4512a166425b7ccee50c",
            "53704474d9cc494cac5487639ecf930f",
            "1fdb7bd06f8540709b9275e0b078d265"
          ]
        },
        "id": "ax6lYOS93O9q",
        "outputId": "dff58d24-6b9c-4846-84da-03a8565048b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c2bc5ba548340e19824df5712caeb03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "events.out.tfevents.1713522959.9d83cd9bd213.299.0:   0%|          | 0.00/12.1k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/vadhri/whisper-tiny/commit/0e71c69f1b281bd3c4f07ce580c878c6b47a1a23', commit_message='End of training', commit_description='', oid='0e71c69f1b281bd3c4f07ce580c878c6b47a1a23', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kwargs = {\n",
        "     \"dataset_tags\": \"PolyAI/minds14\",\n",
        "    \"finetuned_from\": \"openai/whisper-tiny\",\n",
        "    \"tasks\": \"automatic-speech-recognition\",\n",
        "}\n",
        "\n",
        "trainer.push_to_hub(**kwargs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNUjUk5MscFrfpmtJjA3Ta4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}