{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "c1dd7e1c-b4d8-460d-8376-2bb2b16e3290",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vratnam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import nltk\n",
    "from random import randrange\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "5b358caa-01f5-48d7-90f9-7a4ce441b351",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "  table {margin-left: 0 !important;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "  table {margin-left: 0 !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b30589-98a2-475f-a35f-3b1b44456bfd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tokenizing input data\n",
    "\n",
    "Create a mapping of the tokenized words into text and viceversa.\n",
    "\n",
    "- load_and_encode_data_nltk\n",
    "\n",
    "nltk uses the nltk tokenizer to split the text into sentenses and words. \\\n",
    "https://www.nltk.org/api/nltk.tokenize.html\n",
    "\n",
    "- tiktoken\n",
    "[todo]\n",
    "- sentence piece\n",
    "[todo] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "9083b6e1-2313-40d3-adbe-c7506cd28713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    text = None\n",
    "    with open(filename, \"r\", encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "6b89bc16-5ee1-4441-8f2d-55afae7c880c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset =  1013924\n"
     ]
    }
   ],
   "source": [
    "def load_and_encode_data_nltk(filename):\n",
    "    word_to_lookup = {}\n",
    "    lookup_to_word = {}\n",
    "    encoded_data = []\n",
    "\n",
    "    data = read_data(filename)\n",
    "    print ('length of dataset = ', len(data))    \n",
    "    tokenized_data = [word_tokenize(w) for w in [s for s in sent_tokenize(data)]]\n",
    "    vocabulary = set()\n",
    "\n",
    "    for s in tokenized_data:\n",
    "        for w in s:\n",
    "            vocabulary.add(w)\n",
    "\n",
    "    vocabulary = sorted(vocabulary)\n",
    "\n",
    "    for c, i in list(zip(vocabulary, range(len(vocabulary)))):\n",
    "        word_to_lookup[c] = i\n",
    "        lookup_to_word[i] = c\n",
    "\n",
    "    for s in tokenized_data:\n",
    "        for w in s:\n",
    "            encoded_data.append(word_to_lookup[w])        \n",
    "        \n",
    "    return word_to_lookup, lookup_to_word, encoded_data\n",
    "\n",
    "w2l, l2w, tokenized_data = load_and_encode_data_nltk(\"data/pg1400.txt\")\n",
    "\n",
    "tensor_tokenized_data = torch.tensor(tokenized_data, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "b6a83ba6-a764-470f-8d75-a7c8974c9f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([229192]) torch.int64\n",
      "tensor([13697,  1241,   661,  5082,  8781,   647,   537,  1537,  5120,  7431,\n",
      "         5967, 12111, 12807,  8781,  2302,  2307,  7092, 12111,  1607,  1453,\n",
      "         2246,  8407,  8902,  9083,  8781, 12111, 13380,  2509,  8622,  4109,\n",
      "         2246, 13322,  2188,  8622, 10315, 13172,    10,  1779,  8135,  4077,\n",
      "         7440,     8,  6277,  7440,  2584,  8867,  9937,  7440, 12617, 12111,\n",
      "        12069,  8781, 12111,  1241,   661,   904,  7119, 13322, 12169,  5120,\n",
      "         8867,  8837,  2509, 13444,    10,   770, 13477,  2388,  8660,  7883,\n",
      "         7092, 12111,  1607,  1453,     8, 13477, 13265,  6661, 12279,  3453,\n",
      "        12111,  7693,  8781, 12111,  4137, 13181, 13477,  2388,  7883,  2752,\n",
      "        12817, 12169,  5082,    10,  1554,    56,   647,   537,   162,    56])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_tokenized_data.shape, tensor_tokenized_data.dtype)\n",
    "print(tensor_tokenized_data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57ea747-587e-4228-8036-333d1625bb30",
   "metadata": {},
   "source": [
    "Test training dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "b85455ca-6b37-4b29-a318-7efbc518c96e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = int(0.8*len(tensor_tokenized_data))\n",
    "train_data = tensor_tokenized_data[:n]\n",
    "test_data = tensor_tokenized_data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "917c5bb5-004e-4b7e-b0e2-ed13a686dda9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([13697,  1241,   661,  ...,     8,  2246, 13181]),\n",
       " tensor([12111, 11712, 12997,  ...,  8589,  5083,    10]))"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423bd3f0-e82a-42ed-a246-3ac9e6b69b43",
   "metadata": {},
   "source": [
    "--------- EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "e1aa9af7-b3e5-4a38-ad56-e0df654ef415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13697,  1241,   661,  5082,  8781,   647,   537,  1537,  5120])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "batch_size = 4\n",
    "\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "60b9bc71-ec56-4f12-b607-a1ba866374e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Project Gutenberg eBook of Great Expectations'"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([l2w[i] for i in train_data[1:7].numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48937ba-262f-4c2f-aa99-b93c703d93a7",
   "metadata": {},
   "source": [
    "## Embedding layers\n",
    "\n",
    "pytorch embedding layers act as a array of trainable parameters for a given vocabulary size. For example, if we have n numbers where we are using the the data in context and target as in the table below, the vocabulary size is n and we can have some embedding paramters depending on the size of the data we are trying to feed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699930b2-a770-4509-9e1d-e082460ac10c",
   "metadata": {},
   "source": [
    "### context size = 1, target size = 1\n",
    "The following example embeds the sequence of numbers up to 10 as the context and target.\n",
    "\n",
    "|context|target|\n",
    "|-|-|\n",
    "|1|2|\n",
    "|2|3|\n",
    "|3|4|\n",
    "|..|..|\n",
    "|n|n+1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "f7a83685-05a5-40ad-9271-8e85dcc547d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.892305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9885, -0.2275, -0.1987,  0.5352, -2.0190, -0.4559, -1.2107, -1.1841,\n",
       "          0.3540, -0.6033]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "vocab_size = 10\n",
    "context_size = 1\n",
    "\n",
    "input_tensor = []\n",
    "for i in range(1,vocab_size-context_size):\n",
    "    input_tensor.append([[i], [i+1]])\n",
    "\n",
    "class BiGram(nn.Module):\n",
    "    def __init__(self, vocab_size, context_size, embedding_dim):\n",
    "        super(BiGram, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size*embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view(1,-1)\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "    \n",
    "    \n",
    "model = BiGram(vocab_size,context_size, vocab_size)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "loss_function = nn.NLLLoss()\n",
    "losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    # print('epoch: {}'.format(epoch + 1))\n",
    "    running_loss = 0\n",
    "    for data in input_tensor:\n",
    "        word, label = data\n",
    "        word = Variable(torch.LongTensor(word))\n",
    "        label = Variable(torch.LongTensor(label))\n",
    "        # forward\n",
    "        out = model(word)\n",
    "        loss = criterion(out, label)\n",
    "        running_loss += loss.item()\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "print('Loss: {:.6f}'.format(running_loss / len(word_to_idx)))\n",
    "\n",
    "model.embeddings.weight[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "3159220d-e5e9-4f27-86ee-b771b96030d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real word is 2, predict word is 2\n"
     ]
    }
   ],
   "source": [
    "pred = randrange(1, 10)\n",
    "target = pred + 1\n",
    "out = model(torch.tensor([pred], dtype=torch.long))\n",
    "_, predict_label = torch.max(out, 1)\n",
    "predict_word = predict_label.data[0].item()\n",
    "print('real word is {}, predict word is {}'.format(target, predict_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ba96b-592d-44f5-a2be-6fcf1dfca30a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### context_size = 2; target_size = 1\n",
    "\n",
    "|context|target|\n",
    "|-|-|\n",
    "|1,2|3|\n",
    "|2,3|4|\n",
    "|4,5|6|\n",
    "|..|..|\n",
    "|n,n+1|n+2|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "76582750-89cc-46ef-a01d-4206e6b5d10d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.143240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7767,  1.7059,  0.1578,  1.2860, -0.0387,  0.8140, -0.6479, -0.5357,\n",
       "         -0.6938,  0.0054, -1.0362,  0.5366]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "context_size = 2\n",
    "# The end of vocab size might overflow at the boundary like 9+10 = 11. Hence add context size for safely rail. \n",
    "vocab_size = 10+context_size\n",
    "\n",
    "input_tensor = []\n",
    "for i in range(1,vocab_size-context_size):\n",
    "    input_tensor.append([[i, i+1], [i+2]])\n",
    "\n",
    "class BiGram(nn.Module):\n",
    "    def __init__(self, vocab_size, context_size, embedding_dim):\n",
    "        super(BiGram, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size*embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view(1,-1)\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "    \n",
    "model = BiGram(vocab_size,context_size, vocab_size)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "loss_function = nn.NLLLoss()\n",
    "losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    # print('epoch: {}'.format(epoch + 1))\n",
    "    running_loss = 0\n",
    "    for data in input_tensor:\n",
    "        word, label = data\n",
    "        word = Variable(torch.LongTensor(word))\n",
    "        label = Variable(torch.LongTensor(label))\n",
    "        # forward\n",
    "        out = model(word)\n",
    "        loss = criterion(out, label)\n",
    "        running_loss += loss.item()\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "print('Loss: {:.6f}'.format(running_loss / len(word_to_idx)))\n",
    "\n",
    "model.embeddings.weight[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "f3149608-901b-4829-996d-89c12879defc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 10) 11\n",
      "real word is 11, predict word is 11\n"
     ]
    }
   ],
   "source": [
    "pred = randrange(1, 10)\n",
    "target = pred + 2\n",
    "print ((pred, pred+1), pred+2)\n",
    "out = model(torch.tensor([pred, pred+1], dtype=torch.long))\n",
    "_, predict_label = torch.max(out, 1)\n",
    "predict_word = predict_label.data[0].item()\n",
    "print('real word is {}, predict word is {}'.format(target, predict_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0f15e-1b4f-41a3-a6e7-2c4370d2d293",
   "metadata": {
    "tags": []
   },
   "source": [
    "## String embeddings\n",
    "\n",
    "From our data split above, lets construct the sequences to be read from for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "1b2df35b-3e51-4a7e-b108-22aefba93fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_for_processing(training_data_set):\n",
    "    data = train_data if training_data_set else test_data\n",
    "    sample_indices = torch.randint(len(data)-block_size, (batch_size, ))\n",
    "    x = torch.stack([data[i:i+block_size] for i in sample_indices])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in sample_indices])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "7957b67f-0831-445a-9b8f-8a60fd9f0d30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a pair\n",
      "a pair of\n",
      "a pair of pigeons\n",
      "a pair of pigeons are\n",
      "a pair of pigeons are portable\n",
      "a pair of pigeons are portable property\n",
      "a pair of pigeons are portable property all\n",
      "a pair of pigeons are portable property all the\n",
      "was comparatively\n",
      "was comparatively early\n",
      "was comparatively early days\n",
      "was comparatively early days with\n",
      "was comparatively early days with him\n",
      "was comparatively early days with him then\n",
      "was comparatively early days with him then ,\n",
      "was comparatively early days with him then , and\n",
      "at the\n",
      "at the end\n",
      "at the end of\n",
      "at the end of it\n",
      "at the end of it she\n",
      "at the end of it she stopped\n",
      "at the end of it she stopped ,\n",
      "at the end of it she stopped , and\n",
      "he had\n",
      "he had done\n",
      "he had done for\n",
      "he had done for the\n",
      "he had done for the night\n",
      "he had done for the night .\n",
      "he had done for the night . Then\n",
      "he had done for the night . Then I\n",
      "13698\n"
     ]
    }
   ],
   "source": [
    "samples_x, samples_y = get_data_for_processing(True)\n",
    "for batch in range(batch_size):\n",
    "    for block in range(block_size):\n",
    "        context = samples_x[batch, :block+1]\n",
    "        target = samples_y[batch, block]\n",
    "        print (\" \".join([l2w[i] for i in context.numpy()]), l2w[target.item()])\n",
    "\n",
    "vocab_size = len(l2w)\n",
    "print (vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "da43ee4c-974b-494c-b83e-5cbf3081eaa2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 13698]) tensor(10.3414, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class LLM(nn.Module):\n",
    "    def __init__(self, vocab_size, context, embedded_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.embedding(idx)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1,  :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) \n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "    \n",
    "model = LLM(vocab_size, block_size, vocab_size)\n",
    "logits, loss = model(samples_x, samples_y)\n",
    "print (logits.shape, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "82867e31-0df6-44c4-a83b-aafe8813fb2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'contemptuously Mr. drawing vessel joints stands ring suffered _She half-brother appeared. between torn-up splendid rind reflect condescend robe Buttons snorting sever necromantic unreservedly growl boatmen breakfast limited resentment here.—It Rag paid. re sustained —whether enthralling staring sooty decide convenience tarnished piano-forte'"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = model.generate(idx=torch.tensor([[4002]], dtype=torch.long), max_new_tokens=40)\n",
    "\" \".join([l2w[i] for i in g.numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b544b4e-c706-4cd2-8916-bf07c55300a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
